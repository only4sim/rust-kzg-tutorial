# 第11章：高级 API 使用指南

> **学习目标**: 掌握 Rust KZG 库的高级API使用技巧，包括批量操作、性能优化、错误处理、企业级应用最佳实践

---

## 11.1 高级API架构概览

### 🏗️ API 设计理念

Rust KZG 库采用分层API设计，提供从低级原语到高级抽象的完整API栈：

```rust
// API 层次结构
┌─────────────────────────────────────┐
│     高级应用API                     │  ← 本章重点
│  (Batch Processing, Streaming)     │
├─────────────────────────────────────┤
│     中级功能API                     │
│  (EIP-4844, EIP-7594, KZG Core)   │
├─────────────────────────────────────┤
│     底层密码学API                   │
│  (Fr, G1, G2, Pairing)            │
└─────────────────────────────────────┘
```

### 🎯 高级API核心特性

1. **批量操作支持**: 高效处理大规模数据集
2. **流式处理**: 内存友好的数据流处理
3. **自适应后端**: 智能硬件检测与性能优化
4. **企业级错误处理**: 完善的错误恢复机制
5. **实时监控**: 性能指标收集与分析
6. **并发安全**: 线程安全的并发操作

---

## 11.2 批量操作与流式处理

### 📦 批量承诺生成

批量操作是处理大规模数据的关键技术，让我们看看如何高效地处理多个blob：

```rust
use rust_kzg_blst::{
    KzgSettings, Fr, G1, 
    eip_4844::{blob_to_kzg_commitment_rust, compute_blob_kzg_proof_rust}
};
use std::sync::Arc;
use rayon::prelude::*;

/// 高级批量处理器
pub struct BatchProcessor {
    settings: Arc<KzgSettings>,
    chunk_size: usize,
    parallel_workers: usize,
}

impl BatchProcessor {
    /// 创建新的批量处理器
    pub fn new(settings: Arc<KzgSettings>) -> Self {
        Self {
            settings,
            chunk_size: 64,  // 默认块大小
            parallel_workers: num_cpus::get(),
        }
    }
    
    /// 配置块大小
    pub fn with_chunk_size(mut self, size: usize) -> Self {
        self.chunk_size = size;
        self
    }
    
    /// 批量生成承诺
    pub fn batch_commitments(&self, blobs: &[Vec<Fr>]) -> Result<Vec<G1>, String> {
        // 分块处理以平衡内存使用和并行度
        blobs
            .par_chunks(self.chunk_size)
            .map(|chunk| {
                chunk
                    .iter()
                    .map(|blob| blob_to_kzg_commitment_rust(blob, &self.settings))
                    .collect::<Result<Vec<_>, _>>()
            })
            .collect::<Result<Vec<_>, _>>()
            .map(|chunks| chunks.into_iter().flatten().collect())
    }
    
    /// 批量生成证明
    pub fn batch_proofs(&self, blobs: &[Vec<Fr>], commitments: &[G1]) 
        -> Result<Vec<G1>, String> {
        assert_eq!(blobs.len(), commitments.len());
        
        blobs
            .par_iter()
            .zip(commitments.par_iter())
            .map(|(blob, commitment)| {
                compute_blob_kzg_proof_rust(blob, commitment, &self.settings)
            })
            .collect()
    }
}
```

### 🌊 流式处理架构

对于超大规模数据，流式处理可以显著降低内存占用：

```rust
use std::io::{Read, BufReader};
use std::fs::File;

/// 流式数据处理器
pub struct StreamProcessor {
    settings: Arc<KzgSettings>,
    buffer_size: usize,
}

impl StreamProcessor {
    /// 创建流式处理器
    pub fn new(settings: Arc<KzgSettings>) -> Self {
        Self {
            settings,
            buffer_size: 4096 * 32, // 128KB 缓冲区
        }
    }
    
    /// 流式处理文件数据
    pub fn process_file<F, R>(&self, 
        file_path: &str, 
        processor: F
    ) -> Result<Vec<R>, Box<dyn std::error::Error>>
    where
        F: Fn(&[u8]) -> Result<R, String> + Sync + Send,
        R: Send,
    {
        let file = File::open(file_path)?;
        let mut reader = BufReader::new(file);
        let mut results = Vec::new();
        let mut buffer = vec![0u8; self.buffer_size];
        
        loop {
            let bytes_read = reader.read(&mut buffer)?;
            if bytes_read == 0 {
                break; // EOF
            }
            
            // 处理数据块
            let result = processor(&buffer[..bytes_read])?;
            results.push(result);
        }
        
        Ok(results)
    }
    
    /// 流式承诺生成
    pub fn stream_commitments<I>(&self, blob_iter: I) -> impl Iterator<Item = Result<G1, String>>
    where
        I: Iterator<Item = Vec<Fr>>,
    {
        blob_iter.map(move |blob| {
            blob_to_kzg_commitment_rust(&blob, &self.settings)
        })
    }
}
```

---

## 11.3 自适应后端选择与性能优化

### 🧠 智能后端选择

不同的工作负载和硬件配置需要不同的优化策略：

```rust
use std::collections::HashMap;
use std::time::{Duration, Instant};

/// 后端性能特征
#[derive(Debug, Clone)]
pub struct BackendProfile {
    pub name: String,
    pub commitment_time: Duration,
    pub proof_time: Duration,
    pub verification_time: Duration,
    pub memory_usage: usize,
    pub cpu_cores: usize,
    pub gpu_available: bool,
}

/// 自适应后端管理器
pub struct AdaptiveBackend {
    profiles: HashMap<String, BackendProfile>,
    current_backend: String,
    performance_history: Vec<(String, Duration)>,
}

impl AdaptiveBackend {
    /// 创建自适应后端管理器
    pub fn new() -> Self {
        Self {
            profiles: HashMap::new(),
            current_backend: "blst".to_string(),
            performance_history: Vec::new(),
        }
    }
    
    /// 注册后端性能配置
    pub fn register_backend(&mut self, profile: BackendProfile) {
        self.profiles.insert(profile.name.clone(), profile);
    }
    
    /// 基于工作负载选择最优后端
    pub fn select_optimal_backend(&mut self, workload_type: WorkloadType) -> String {
        match workload_type {
            WorkloadType::SmallBatch { count } if count < 10 => {
                // 小批量：选择启动开销低的后端
                "arkworks".to_string()
            },
            WorkloadType::LargeBatch { count } if count > 1000 => {
                // 大批量：选择吞吐量高的后端
                if self.has_gpu_backend() {
                    "blst-gpu".to_string()
                } else {
                    "blst".to_string()
                }
            },
            WorkloadType::Streaming => {
                // 流式处理：选择内存效率高的后端
                "constantine".to_string()
            },
            WorkloadType::RealTime => {
                // 实时处理：选择延迟低的后端
                "blst".to_string()
            },
            _ => self.current_backend.clone(),
        }
    }
    
    /// 检测GPU后端可用性
    fn has_gpu_backend(&self) -> bool {
        self.profiles.values().any(|p| p.gpu_available)
    }
    
    /// 记录性能数据
    pub fn record_performance(&mut self, backend: String, duration: Duration) {
        self.performance_history.push((backend, duration));
        
        // 保持历史记录在合理范围内
        if self.performance_history.len() > 1000 {
            self.performance_history.drain(0..500);
        }
    }
    
    /// 获取性能统计
    pub fn get_performance_stats(&self) -> HashMap<String, (Duration, usize)> {
        let mut stats = HashMap::new();
        
        for (backend, duration) in &self.performance_history {
            let entry = stats.entry(backend.clone()).or_insert((Duration::new(0, 0), 0));
            entry.0 += *duration;
            entry.1 += 1;
        }
        
        // 计算平均值
        for (_, (total_time, count)) in stats.iter_mut() {
            if *count > 0 {
                *total_time = *total_time / *count as u32;
            }
        }
        
        stats
    }
}

/// 工作负载类型
#[derive(Debug, Clone)]
pub enum WorkloadType {
    SmallBatch { count: usize },
    LargeBatch { count: usize },
    Streaming,
    RealTime,
    Interactive,
}
```

### ⚡ 性能监控与优化

实时性能监控帮助我们及时发现和解决性能问题：

```rust
use std::sync::{Arc, Mutex};
use std::time::Instant;

/// 性能指标收集器
#[derive(Debug, Clone)]
pub struct PerformanceMetrics {
    pub operations_count: u64,
    pub total_time: Duration,
    pub average_time: Duration,
    pub min_time: Duration,
    pub max_time: Duration,
    pub memory_peak: usize,
    pub error_count: u64,
}

impl Default for PerformanceMetrics {
    fn default() -> Self {
        Self {
            operations_count: 0,
            total_time: Duration::new(0, 0),
            average_time: Duration::new(0, 0),
            min_time: Duration::new(u64::MAX, 0),
            max_time: Duration::new(0, 0),
            memory_peak: 0,
            error_count: 0,
        }
    }
}

/// 性能监控器
pub struct PerformanceMonitor {
    metrics: Arc<Mutex<PerformanceMetrics>>,
    enable_detailed_logging: bool,
}

impl PerformanceMonitor {
    /// 创建性能监控器
    pub fn new() -> Self {
        Self {
            metrics: Arc::new(Mutex::new(PerformanceMetrics::default())),
            enable_detailed_logging: false,
        }
    }
    
    /// 启用详细日志
    pub fn enable_detailed_logging(mut self) -> Self {
        self.enable_detailed_logging = true;
        self
    }
    
    /// 测量操作性能
    pub fn measure<F, R>(&self, operation_name: &str, operation: F) -> Result<R, String>
    where
        F: FnOnce() -> Result<R, String>,
    {
        let start_time = Instant::now();
        let start_memory = self.get_memory_usage();
        
        let result = operation();
        
        let duration = start_time.elapsed();
        let end_memory = self.get_memory_usage();
        
        // 更新指标
        self.update_metrics(duration, end_memory, result.is_err());
        
        if self.enable_detailed_logging {
            println!("Operation '{}': {:?} (Memory: {} -> {} bytes)", 
                operation_name, duration, start_memory, end_memory);
        }
        
        result
    }
    
    /// 更新性能指标
    fn update_metrics(&self, duration: Duration, memory_usage: usize, is_error: bool) {
        let mut metrics = self.metrics.lock().unwrap();
        
        metrics.operations_count += 1;
        metrics.total_time += duration;
        
        if duration < metrics.min_time {
            metrics.min_time = duration;
        }
        if duration > metrics.max_time {
            metrics.max_time = duration;
        }
        
        metrics.average_time = metrics.total_time / metrics.operations_count as u32;
        
        if memory_usage > metrics.memory_peak {
            metrics.memory_peak = memory_usage;
        }
        
        if is_error {
            metrics.error_count += 1;
        }
    }
    
    /// 获取当前内存使用量（简化实现）
    fn get_memory_usage(&self) -> usize {
        // 在实际实现中，这里应该使用系统调用获取真实内存使用量
        // 这里使用模拟值
        1024 * 1024 // 1MB
    }
    
    /// 获取性能报告
    pub fn get_report(&self) -> PerformanceMetrics {
        self.metrics.lock().unwrap().clone()
    }
    
    /// 重置性能指标
    pub fn reset(&self) {
        let mut metrics = self.metrics.lock().unwrap();
        *metrics = PerformanceMetrics::default();
    }
}
```

---

## 11.4 企业级错误处理与恢复

### 🛡️ 多层错误处理策略

企业级应用需要健壮的错误处理机制：

```rust
use std::fmt;
use std::error::Error as StdError;

/// 自定义错误类型
#[derive(Debug)]
pub enum KzgAdvancedError {
    /// 配置错误
    Configuration { message: String },
    /// 数据验证错误
    DataValidation { field: String, value: String },
    /// 性能错误
    Performance { operation: String, expected_time: Duration, actual_time: Duration },
    /// 资源不足错误
    ResourceExhausted { resource: String, limit: usize },
    /// 后端错误
    Backend { backend: String, inner: Box<dyn StdError + Send + Sync> },
    /// 网络错误
    Network { endpoint: String, inner: Box<dyn StdError + Send + Sync> },
}

impl fmt::Display for KzgAdvancedError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            KzgAdvancedError::Configuration { message } => {
                write!(f, "Configuration error: {}", message)
            },
            KzgAdvancedError::DataValidation { field, value } => {
                write!(f, "Data validation failed for field '{}' with value '{}'", field, value)
            },
            KzgAdvancedError::Performance { operation, expected_time, actual_time } => {
                write!(f, "Performance degradation in '{}': expected {:?}, actual {:?}", 
                    operation, expected_time, actual_time)
            },
            KzgAdvancedError::ResourceExhausted { resource, limit } => {
                write!(f, "Resource '{}' exhausted, limit: {}", resource, limit)
            },
            KzgAdvancedError::Backend { backend, inner } => {
                write!(f, "Backend '{}' error: {}", backend, inner)
            },
            KzgAdvancedError::Network { endpoint, inner } => {
                write!(f, "Network error with '{}': {}", endpoint, inner)
            },
        }
    }
}

impl StdError for KzgAdvancedError {
    fn source(&self) -> Option<&(dyn StdError + 'static)> {
        match self {
            KzgAdvancedError::Backend { inner, .. } => Some(inner.as_ref()),
            KzgAdvancedError::Network { inner, .. } => Some(inner.as_ref()),
            _ => None,
        }
    }
}

/// 错误恢复策略
#[derive(Debug, Clone)]
pub enum RecoveryStrategy {
    /// 重试操作
    Retry { max_attempts: usize, delay: Duration },
    /// 回退到备用方案
    Fallback { alternative: String },
    /// 降级服务
    Degrade { level: u8 },
    /// 失败快速返回
    FailFast,
}

/// 企业级KZG操作管理器
pub struct EnterpriseKzgManager {
    primary_backend: String,
    fallback_backends: Vec<String>,
    error_recovery: HashMap<String, RecoveryStrategy>,
    circuit_breaker: CircuitBreaker,
    audit_logger: AuditLogger,
}

impl EnterpriseKzgManager {
    /// 创建企业级管理器
    pub fn new(primary_backend: String) -> Self {
        Self {
            primary_backend,
            fallback_backends: vec!["arkworks".to_string(), "constantine".to_string()],
            error_recovery: HashMap::new(),
            circuit_breaker: CircuitBreaker::new(5, Duration::from_secs(60)),
            audit_logger: AuditLogger::new(),
        }
    }
    
    /// 执行带恢复的操作
    pub async fn execute_with_recovery<F, R>(&mut self, 
        operation_name: &str, 
        operation: F
    ) -> Result<R, KzgAdvancedError>
    where
        F: Fn() -> Result<R, String> + Clone,
    {
        let start_time = Instant::now();
        
        // 检查断路器状态
        if !self.circuit_breaker.can_execute() {
            return Err(KzgAdvancedError::ResourceExhausted {
                resource: "circuit_breaker".to_string(),
                limit: self.circuit_breaker.failure_threshold,
            });
        }
        
        // 获取恢复策略
        let strategy = self.error_recovery
            .get(operation_name)
            .cloned()
            .unwrap_or(RecoveryStrategy::Retry { max_attempts: 3, delay: Duration::from_millis(100) });
        
        match strategy {
            RecoveryStrategy::Retry { max_attempts, delay } => {
                for attempt in 1..=max_attempts {
                    match operation() {
                        Ok(result) => {
                            self.circuit_breaker.record_success();
                            self.audit_logger.log_success(operation_name, start_time.elapsed());
                            return Ok(result);
                        },
                        Err(e) if attempt < max_attempts => {
                            self.audit_logger.log_retry(operation_name, attempt, &e);
                            tokio::time::sleep(delay).await;
                            continue;
                        },
                        Err(e) => {
                            self.circuit_breaker.record_failure();
                            self.audit_logger.log_failure(operation_name, &e);
                            return Err(KzgAdvancedError::Backend {
                                backend: self.primary_backend.clone(),
                                inner: Box::new(SimpleError::new(e)),
                            });
                        }
                    }
                }
            },
            RecoveryStrategy::Fallback { alternative } => {
                match operation() {
                    Ok(result) => Ok(result),
                    Err(_) => {
                        // 切换到备用后端
                        self.audit_logger.log_fallback(operation_name, &alternative);
                        // 这里应该使用备用后端重新执行操作
                        operation() // 简化实现
                            .map_err(|e| KzgAdvancedError::Backend {
                                backend: alternative,
                                inner: Box::new(SimpleError::new(e)),
                            })
                    }
                }
            },
            _ => {
                operation().map_err(|e| KzgAdvancedError::Backend {
                    backend: self.primary_backend.clone(),
                    inner: Box::new(SimpleError::new(e)),
                })
            }
        }
    }
}

/// 断路器实现
#[derive(Debug)]
pub struct CircuitBreaker {
    failure_count: usize,
    failure_threshold: usize,
    timeout: Duration,
    last_failure_time: Option<Instant>,
    state: CircuitBreakerState,
}

#[derive(Debug, PartialEq)]
enum CircuitBreakerState {
    Closed,   // 正常状态
    Open,     // 断开状态
    HalfOpen, // 半开状态
}

impl CircuitBreaker {
    fn new(failure_threshold: usize, timeout: Duration) -> Self {
        Self {
            failure_count: 0,
            failure_threshold,
            timeout,
            last_failure_time: None,
            state: CircuitBreakerState::Closed,
        }
    }
    
    fn can_execute(&mut self) -> bool {
        match self.state {
            CircuitBreakerState::Closed => true,
            CircuitBreakerState::Open => {
                if let Some(last_failure) = self.last_failure_time {
                    if last_failure.elapsed() > self.timeout {
                        self.state = CircuitBreakerState::HalfOpen;
                        true
                    } else {
                        false
                    }
                } else {
                    true
                }
            },
            CircuitBreakerState::HalfOpen => true,
        }
    }
    
    fn record_success(&mut self) {
        self.failure_count = 0;
        self.state = CircuitBreakerState::Closed;
    }
    
    fn record_failure(&mut self) {
        self.failure_count += 1;
        self.last_failure_time = Some(Instant::now());
        
        if self.failure_count >= self.failure_threshold {
            self.state = CircuitBreakerState::Open;
        }
    }
}

/// 审计日志记录器
#[derive(Debug)]
pub struct AuditLogger {
    logs: Vec<AuditEvent>,
}

#[derive(Debug)]
pub struct AuditEvent {
    timestamp: Instant,
    operation: String,
    event_type: AuditEventType,
    details: String,
}

#[derive(Debug)]
pub enum AuditEventType {
    Success,
    Failure,
    Retry,
    Fallback,
}

impl AuditLogger {
    fn new() -> Self {
        Self { logs: Vec::new() }
    }
    
    fn log_success(&mut self, operation: &str, duration: Duration) {
        self.logs.push(AuditEvent {
            timestamp: Instant::now(),
            operation: operation.to_string(),
            event_type: AuditEventType::Success,
            details: format!("Duration: {:?}", duration),
        });
    }
    
    fn log_failure(&mut self, operation: &str, error: &str) {
        self.logs.push(AuditEvent {
            timestamp: Instant::now(),
            operation: operation.to_string(),
            event_type: AuditEventType::Failure,
            details: error.to_string(),
        });
    }
    
    fn log_retry(&mut self, operation: &str, attempt: usize, error: &str) {
        self.logs.push(AuditEvent {
            timestamp: Instant::now(),
            operation: operation.to_string(),
            event_type: AuditEventType::Retry,
            details: format!("Attempt {}: {}", attempt, error),
        });
    }
    
    fn log_fallback(&mut self, operation: &str, fallback_backend: &str) {
        self.logs.push(AuditEvent {
            timestamp: Instant::now(),
            operation: operation.to_string(),
            event_type: AuditEventType::Fallback,
            details: format!("Switched to backend: {}", fallback_backend),
        });
    }
}

/// 简单错误类型
#[derive(Debug)]
struct SimpleError {
    message: String,
}

impl SimpleError {
    fn new(message: String) -> Self {
        Self { message }
    }
}

impl fmt::Display for SimpleError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{}", self.message)
    }
}

impl StdError for SimpleError {}
```

---

## 11.5 内存管理与零拷贝优化

### 🚀 Arena分配器优化

对于大规模数据处理，智能的内存管理可以显著提升性能：

```rust
use std::alloc::{alloc, dealloc, Layout};
use std::ptr::NonNull;
use std::marker::PhantomData;

/// Arena内存分配器
pub struct Arena {
    chunks: Vec<Chunk>,
    current_chunk: usize,
    current_pos: usize,
}

struct Chunk {
    data: NonNull<u8>,
    size: usize,
    capacity: usize,
}

impl Arena {
    /// 创建新的Arena分配器
    pub fn new() -> Self {
        Self::with_capacity(1024 * 1024) // 1MB 初始大小
    }
    
    /// 创建指定容量的Arena分配器
    pub fn with_capacity(capacity: usize) -> Self {
        let mut arena = Self {
            chunks: Vec::new(),
            current_chunk: 0,
            current_pos: 0,
        };
        arena.add_chunk(capacity);
        arena
    }
    
    /// 添加新的内存块
    fn add_chunk(&mut self, size: usize) {
        let layout = Layout::from_size_align(size, 8).unwrap();
        let data = unsafe { alloc(layout) };
        
        if data.is_null() {
            panic!("Arena allocation failed");
        }
        
        self.chunks.push(Chunk {
            data: NonNull::new(data).unwrap(),
            size: 0,
            capacity: size,
        });
    }
    
    /// 分配内存
    pub fn alloc<T>(&mut self, count: usize) -> &mut [T] {
        let size = std::mem::size_of::<T>() * count;
        let align = std::mem::align_of::<T>();
        
        // 确保当前位置正确对齐
        let current_pos = (self.current_pos + align - 1) & !(align - 1);
        
        if let Some(chunk) = self.chunks.get_mut(self.current_chunk) {
            if current_pos + size <= chunk.capacity {
                let ptr = unsafe { chunk.data.as_ptr().add(current_pos) as *mut T };
                self.current_pos = current_pos + size;
                chunk.size = self.current_pos;
                
                return unsafe { std::slice::from_raw_parts_mut(ptr, count) };
            }
        }
        
        // 需要新的内存块
        let new_chunk_size = std::cmp::max(size * 2, 1024 * 1024);
        self.add_chunk(new_chunk_size);
        self.current_chunk = self.chunks.len() - 1;
        self.current_pos = 0;
        
        self.alloc(count)
    }
    
    /// 重置Arena（保留内存块）
    pub fn reset(&mut self) {
        self.current_chunk = 0;
        self.current_pos = 0;
        for chunk in &mut self.chunks {
            chunk.size = 0;
        }
    }
    
    /// 获取已使用的内存大小
    pub fn used_memory(&self) -> usize {
        self.chunks.iter().map(|chunk| chunk.size).sum()
    }
    
    /// 获取总分配的内存大小
    pub fn total_memory(&self) -> usize {
        self.chunks.iter().map(|chunk| chunk.capacity).sum()
    }
}

impl Drop for Arena {
    fn drop(&mut self) {
        for chunk in &self.chunks {
            let layout = Layout::from_size_align(chunk.capacity, 8).unwrap();
            unsafe {
                dealloc(chunk.data.as_ptr(), layout);
            }
        }
    }
}

/// 零拷贝数据视图
pub struct ZeroCopyView<'a, T> {
    data: &'a [T],
    _phantom: PhantomData<T>,
}

impl<'a, T> ZeroCopyView<'a, T> {
    /// 创建零拷贝视图
    pub fn new(data: &'a [T]) -> Self {
        Self {
            data,
            _phantom: PhantomData,
        }
    }
    
    /// 获取数据切片
    pub fn as_slice(&self) -> &[T] {
        self.data
    }
    
    /// 创建子视图
    pub fn subview(&self, start: usize, len: usize) -> Option<ZeroCopyView<'a, T>> {
        if start + len <= self.data.len() {
            Some(ZeroCopyView::new(&self.data[start..start + len]))
        } else {
            None
        }
    }
}

/// 内存池管理器
pub struct MemoryPool<T> {
    pool: Vec<Vec<T>>,
    capacity: usize,
    max_size: usize,
}

impl<T: Default + Clone> MemoryPool<T> {
    /// 创建内存池
    pub fn new(capacity: usize, max_size: usize) -> Self {
        Self {
            pool: Vec::with_capacity(max_size),
            capacity,
            max_size,
        }
    }
    
    /// 获取对象
    pub fn get(&mut self) -> Vec<T> {
        self.pool.pop().unwrap_or_else(|| {
            vec![T::default(); self.capacity]
        })
    }
    
    /// 归还对象
    pub fn put(&mut self, mut obj: Vec<T>) {
        if self.pool.len() < self.max_size {
            obj.clear();
            obj.resize(self.capacity, T::default());
            self.pool.push(obj);
        }
        // 如果池已满，就让对象被Drop
    }
    
    /// 获取池大小
    pub fn size(&self) -> usize {
        self.pool.len()
    }
}
```

---

## 11.6 并发安全与多线程优化

### 🔄 线程安全的并发操作

在多线程环境中安全地使用KZG操作：

```rust
use std::sync::{Arc, RwLock, Mutex};
use std::sync::atomic::{AtomicUsize, Ordering};
use std::thread;
use crossbeam_channel::{bounded, Receiver, Sender};

/// 线程安全的KZG处理器
pub struct ConcurrentKzgProcessor {
    settings: Arc<KzgSettings>,
    worker_count: usize,
    task_queue: Sender<KzgTask>,
    result_queue: Receiver<KzgResult>,
    active_workers: Arc<AtomicUsize>,
    statistics: Arc<RwLock<ProcessingStatistics>>,
}

/// KZG任务类型
#[derive(Debug)]
pub enum KzgTask {
    Commitment { id: u64, blob: Vec<Fr> },
    Proof { id: u64, blob: Vec<Fr>, commitment: G1 },
    Verification { id: u64, commitment: G1, proof: G1, point: Fr, value: Fr },
    BatchCommitment { id: u64, blobs: Vec<Vec<Fr>> },
}

/// 任务结果
#[derive(Debug)]
pub enum KzgResult {
    Commitment { id: u64, result: Result<G1, String> },
    Proof { id: u64, result: Result<G1, String> },
    Verification { id: u64, result: Result<bool, String> },
    BatchCommitment { id: u64, result: Result<Vec<G1>, String> },
}

/// 处理统计信息
#[derive(Debug, Default)]
pub struct ProcessingStatistics {
    pub total_tasks: usize,
    pub completed_tasks: usize,
    pub failed_tasks: usize,
    pub average_processing_time: Duration,
    pub peak_concurrent_tasks: usize,
}

impl ConcurrentKzgProcessor {
    /// 创建并发处理器
    pub fn new(settings: Arc<KzgSettings>, worker_count: usize) -> Self {
        let (task_sender, task_receiver) = bounded(1000);
        let (result_sender, result_receiver) = bounded(1000);
        
        let processor = Self {
            settings: Arc::clone(&settings),
            worker_count,
            task_queue: task_sender,
            result_queue: result_receiver,
            active_workers: Arc::new(AtomicUsize::new(0)),
            statistics: Arc::new(RwLock::new(ProcessingStatistics::default())),
        };
        
        // 启动工作线程
        for worker_id in 0..worker_count {
            let settings = Arc::clone(&settings);
            let task_receiver = task_receiver.clone();
            let result_sender = result_sender.clone();
            let active_workers = Arc::clone(&processor.active_workers);
            let statistics = Arc::clone(&processor.statistics);
            
            thread::spawn(move || {
                Self::worker_thread(
                    worker_id,
                    settings,
                    task_receiver,
                    result_sender,
                    active_workers,
                    statistics,
                );
            });
        }
        
        processor
    }
    
    /// 工作线程函数
    fn worker_thread(
        worker_id: usize,
        settings: Arc<KzgSettings>,
        task_receiver: Receiver<KzgTask>,
        result_sender: Sender<KzgResult>,
        active_workers: Arc<AtomicUsize>,
        statistics: Arc<RwLock<ProcessingStatistics>>,
    ) {
        println!("Worker {} started", worker_id);
        
        while let Ok(task) = task_receiver.recv() {
            active_workers.fetch_add(1, Ordering::SeqCst);
            let start_time = Instant::now();
            
            let result = match task {
                KzgTask::Commitment { id, blob } => {
                    let result = blob_to_kzg_commitment_rust(&blob, &settings);
                    KzgResult::Commitment { id, result }
                },
                KzgTask::Proof { id, blob, commitment } => {
                    let result = compute_blob_kzg_proof_rust(&blob, &commitment, &settings);
                    KzgResult::Proof { id, result }
                },
                KzgTask::BatchCommitment { id, blobs } => {
                    let results: Result<Vec<_>, _> = blobs
                        .iter()
                        .map(|blob| blob_to_kzg_commitment_rust(blob, &settings))
                        .collect();
                    KzgResult::BatchCommitment { id, result: results }
                },
                _ => continue, // 未实现的任务类型
            };
            
            let processing_time = start_time.elapsed();
            
            // 更新统计信息
            {
                let mut stats = statistics.write().unwrap();
                stats.completed_tasks += 1;
                if result.is_error() {
                    stats.failed_tasks += 1;
                }
                
                // 更新平均处理时间
                let total_time = stats.average_processing_time * stats.completed_tasks as u32
                    + processing_time;
                stats.average_processing_time = total_time / (stats.completed_tasks + 1) as u32;
                
                let current_active = active_workers.load(Ordering::SeqCst);
                if current_active > stats.peak_concurrent_tasks {
                    stats.peak_concurrent_tasks = current_active;
                }
            }
            
            if let Err(_) = result_sender.send(result) {
                println!("Worker {}: Failed to send result", worker_id);
                break;
            }
            
            active_workers.fetch_sub(1, Ordering::SeqCst);
        }
        
        println!("Worker {} stopped", worker_id);
    }
    
    /// 提交任务
    pub fn submit_task(&self, task: KzgTask) -> Result<(), String> {
        {
            let mut stats = self.statistics.write().unwrap();
            stats.total_tasks += 1;
        }
        
        self.task_queue.send(task)
            .map_err(|_| "Failed to submit task".to_string())
    }
    
    /// 获取结果
    pub fn get_result(&self, timeout: Duration) -> Option<KzgResult> {
        self.result_queue.recv_timeout(timeout).ok()
    }
    
    /// 获取处理统计信息
    pub fn get_statistics(&self) -> ProcessingStatistics {
        self.statistics.read().unwrap().clone()
    }
    
    /// 获取活跃工作线程数
    pub fn active_workers(&self) -> usize {
        self.active_workers.load(Ordering::SeqCst)
    }
}

impl KzgResult {
    /// 检查结果是否为错误
    fn is_error(&self) -> bool {
        match self {
            KzgResult::Commitment { result, .. } => result.is_err(),
            KzgResult::Proof { result, .. } => result.is_err(),
            KzgResult::Verification { result, .. } => result.is_err(),
            KzgResult::BatchCommitment { result, .. } => result.is_err(),
        }
    }
}
```

---

## 11.7 实际应用案例

### 🌟 企业级数据处理流水线

让我们通过一个完整的企业级案例来展示高级API的综合运用：

```rust
/// 企业级数据处理流水线
pub struct DataProcessingPipeline {
    batch_processor: BatchProcessor,
    concurrent_processor: ConcurrentKzgProcessor,
    performance_monitor: PerformanceMonitor,
    adaptive_backend: AdaptiveBackend,
    memory_pool: MemoryPool<Fr>,
    arena: Arena,
}

impl DataProcessingPipeline {
    /// 创建处理流水线
    pub fn new(settings: Arc<KzgSettings>) -> Self {
        Self {
            batch_processor: BatchProcessor::new(Arc::clone(&settings)),
            concurrent_processor: ConcurrentKzgProcessor::new(Arc::clone(&settings), 8),
            performance_monitor: PerformanceMonitor::new().enable_detailed_logging(),
            adaptive_backend: AdaptiveBackend::new(),
            memory_pool: MemoryPool::new(4096, 100),
            arena: Arena::new(),
        }
    }
    
    /// 处理大规模数据集
    pub async fn process_dataset(&mut self, 
        dataset: &[Vec<u8>]
    ) -> Result<ProcessingReport, KzgAdvancedError> {
        let start_time = Instant::now();
        let mut report = ProcessingReport::new();
        
        println!("Processing dataset with {} items", dataset.len());
        
        // 第一阶段：数据转换和验证
        let blobs = self.performance_monitor.measure("data_conversion", || {
            dataset
                .par_iter()
                .map(|data| self.convert_to_blob(data))
                .collect::<Result<Vec<_>, _>>()
        })?;
        
        report.conversion_time = start_time.elapsed();
        report.blob_count = blobs.len();
        
        // 第二阶段：选择最优处理策略
        let workload_type = if blobs.len() > 1000 {
            WorkloadType::LargeBatch { count: blobs.len() }
        } else {
            WorkloadType::SmallBatch { count: blobs.len() }
        };
        
        let optimal_backend = self.adaptive_backend.select_optimal_backend(workload_type);
        println!("Selected backend: {}", optimal_backend);
        
        // 第三阶段：批量生成承诺
        let commitments = if blobs.len() > 500 {
            // 大批量：使用并发处理
            self.process_large_batch(&blobs).await?
        } else {
            // 小批量：使用批处理
            self.performance_monitor.measure("batch_commitments", || {
                self.batch_processor.batch_commitments(&blobs)
            })?
        };
        
        report.commitment_time = start_time.elapsed() - report.conversion_time;
        
        // 第四阶段：生成证明
        let proofs = self.performance_monitor.measure("batch_proofs", || {
            self.batch_processor.batch_proofs(&blobs, &commitments)
        })?;
        
        report.proof_time = start_time.elapsed() 
            - report.conversion_time 
            - report.commitment_time;
        
        // 第五阶段：验证
        let verification_results = self.performance_monitor.measure("verification", || {
            self.verify_proofs(&blobs, &commitments, &proofs)
        })?;
        
        report.verification_time = start_time.elapsed()
            - report.conversion_time
            - report.commitment_time
            - report.proof_time;
        
        report.total_time = start_time.elapsed();
        report.success_count = verification_results.iter().filter(|&&x| x).count();
        report.failure_count = verification_results.len() - report.success_count;
        
        // 记录性能数据
        self.adaptive_backend.record_performance(optimal_backend, report.total_time);
        
        // 输出报告
        self.print_report(&report);
        
        Ok(report)
    }
    
    /// 处理大批量数据
    async fn process_large_batch(&mut self, blobs: &[Vec<Fr>]) -> Result<Vec<G1>, KzgAdvancedError> {
        let mut commitments = Vec::with_capacity(blobs.len());
        let mut task_id = 0u64;
        
        // 提交所有任务
        for blob in blobs {
            let task = KzgTask::Commitment {
                id: task_id,
                blob: blob.clone(),
            };
            
            self.concurrent_processor.submit_task(task)
                .map_err(|e| KzgAdvancedError::Configuration { message: e })?;
            
            task_id += 1;
        }
        
        // 收集结果
        let timeout = Duration::from_secs(30);
        for _ in 0..blobs.len() {
            if let Some(result) = self.concurrent_processor.get_result(timeout) {
                match result {
                    KzgResult::Commitment { id, result } => {
                        let commitment = result.map_err(|e| KzgAdvancedError::Backend {
                            backend: "concurrent".to_string(),
                            inner: Box::new(SimpleError::new(e)),
                        })?;
                        
                        commitments.push((id, commitment));
                    },
                    _ => continue,
                }
            } else {
                return Err(KzgAdvancedError::Performance {
                    operation: "concurrent_commitments".to_string(),
                    expected_time: Duration::from_secs(10),
                    actual_time: Duration::from_secs(30),
                });
            }
        }
        
        // 按ID排序并返回承诺
        commitments.sort_by_key(|(id, _)| *id);
        Ok(commitments.into_iter().map(|(_, commitment)| commitment).collect())
    }
    
    /// 数据转换
    fn convert_to_blob(&mut self, data: &[u8]) -> Result<Vec<Fr>, String> {
        // 使用内存池获取向量
        let mut blob = self.memory_pool.get();
        blob.clear();
        
        // 将字节数据转换为Fr元素
        for chunk in data.chunks(31) { // BLS12-381 Fr最大31字节
            let mut bytes = [0u8; 32];
            bytes[1..chunk.len() + 1].copy_from_slice(chunk);
            
            match Fr::from_bytes(&bytes) {
                Ok(fr) => blob.push(fr),
                Err(e) => return Err(format!("Failed to convert bytes to Fr: {}", e)),
            }
        }
        
        // 填充到标准大小
        blob.resize(4096, Fr::zero());
        
        Ok(blob)
    }
    
    /// 验证证明
    fn verify_proofs(&self, 
        blobs: &[Vec<Fr>], 
        commitments: &[G1], 
        proofs: &[G1]
    ) -> Result<Vec<bool>, String> {
        blobs
            .par_iter()
            .zip(commitments.par_iter())
            .zip(proofs.par_iter())
            .map(|((blob, commitment), proof)| {
                // 简化的验证逻辑
                // 在实际实现中，这里应该执行完整的KZG验证
                Ok(true) // 模拟验证成功
            })
            .collect()
    }
    
    /// 打印处理报告
    fn print_report(&self, report: &ProcessingReport) {
        println!("\n=== 数据处理报告 ===");
        println!("总处理时间: {:?}", report.total_time);
        println!("数据转换时间: {:?}", report.conversion_time);
        println!("承诺生成时间: {:?}", report.commitment_time);
        println!("证明生成时间: {:?}", report.proof_time);
        println!("验证时间: {:?}", report.verification_time);
        println!("处理的Blob数量: {}", report.blob_count);
        println!("成功验证: {}", report.success_count);
        println!("验证失败: {}", report.failure_count);
        
        let throughput = report.blob_count as f64 / report.total_time.as_secs_f64();
        println!("处理吞吐量: {:.2} blobs/秒", throughput);
        
        // 显示性能统计
        let stats = self.concurrent_processor.get_statistics();
        println!("并发处理统计:");
        println!("  总任务数: {}", stats.total_tasks);
        println!("  完成任务数: {}", stats.completed_tasks);
        println!("  失败任务数: {}", stats.failed_tasks);
        println!("  平均处理时间: {:?}", stats.average_processing_time);
        println!("  峰值并发任务: {}", stats.peak_concurrent_tasks);
        
        // 显示内存使用情况
        println!("内存使用统计:");
        println!("  Arena已使用: {} bytes", self.arena.used_memory());
        println!("  Arena总分配: {} bytes", self.arena.total_memory());
        println!("  内存池大小: {}", self.memory_pool.size());
    }
}

/// 处理报告
#[derive(Debug, Clone)]
pub struct ProcessingReport {
    pub total_time: Duration,
    pub conversion_time: Duration,
    pub commitment_time: Duration,
    pub proof_time: Duration,
    pub verification_time: Duration,
    pub blob_count: usize,
    pub success_count: usize,
    pub failure_count: usize,
}

impl ProcessingReport {
    fn new() -> Self {
        Self {
            total_time: Duration::new(0, 0),
            conversion_time: Duration::new(0, 0),
            commitment_time: Duration::new(0, 0),
            proof_time: Duration::new(0, 0),
            verification_time: Duration::new(0, 0),
            blob_count: 0,
            success_count: 0,
            failure_count: 0,
        }
    }
}
```

---

## 11.8 性能调优最佳实践

### 📈 性能优化策略总结

基于前面章节的内容，这里总结企业级应用的性能优化最佳实践：

#### 1. 硬件层面优化
- **CPU选择**: 优先选择高频率、大缓存的CPU
- **内存配置**: 至少16GB RAM，推荐32GB+
- **GPU加速**: 对于大规模计算，使用NVIDIA RTX 3080+或Tesla V100+
- **存储优化**: 使用NVMe SSD存储受信任设置文件

#### 2. 算法层面优化
- **批量处理**: 单次处理多个blob以摊销固定开销
- **并行计算**: 充分利用多核CPU和GPU并行能力
- **内存局部性**: 优化数据布局以提高缓存命中率
- **预计算**: 缓存常用的中间结果

#### 3. 系统层面优化
- **内存管理**: 使用Arena分配器减少碎片
- **线程调度**: 合理配置工作线程数量
- **资源隔离**: 避免资源竞争和上下文切换
- **错误处理**: 快速失败和智能重试策略

#### 4. 监控与诊断
- **性能指标**: 实时监控处理延迟和吞吐量
- **资源使用**: 监控CPU、内存、GPU使用率
- **错误率**: 跟踪和分析失败模式
- **瓶颈识别**: 使用性能分析工具定位瓶颈

---

## 11.9 本章总结

### 🎯 核心知识点回顾

1. **批量操作**: 学会了使用`BatchProcessor`高效处理大规模数据
2. **流式处理**: 掌握了`StreamProcessor`的内存友好数据处理方式
3. **自适应后端**: 了解了`AdaptiveBackend`的智能硬件检测和性能优化
4. **企业级错误处理**: 学习了多层错误处理、断路器和审计日志
5. **内存管理**: 掌握了Arena分配器和零拷贝优化技术
6. **并发安全**: 学会了线程安全的并发KZG操作
7. **实际应用**: 通过企业级数据处理流水线案例，综合运用了所有技术

### 🚀 下一步学习建议

- **深入GPU编程**: 学习CUDA和OpenCL编程，自定义GPU内核
- **分布式计算**: 探索集群环境下的KZG计算分布
- **微服务架构**: 将KZG功能封装为微服务
- **性能基准**: 建立完整的性能基准测试体系

### 💡 实践练习建议

1. **性能对比测试**: 对比不同后端在你的硬件上的性能表现
2. **内存使用分析**: 使用Valgrind等工具分析内存使用模式
3. **并发压力测试**: 测试高并发场景下的系统稳定性
4. **错误注入测试**: 验证错误处理和恢复机制的有效性

本章的高级API使用指南为你提供了在生产环境中高效、安全地使用Rust KZG库的完整知识体系。这些技术不仅适用于KZG应用，也是高性能Rust应用开发的通用最佳实践。

---

> **下一章预告**: 第12章将深入探讨C语言绑定与跨语言集成，学习如何在不同编程语言中使用Rust KZG库。