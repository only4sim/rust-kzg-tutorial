/*!
# ç¬¬16ç« ï¼šç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ä¸è¿ç»´ - ç¤ºä¾‹ä»£ç 

æœ¬ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•æ„å»ºå’Œéƒ¨ç½²ç”Ÿäº§çº§çš„ KZG æœåŠ¡ï¼ŒåŒ…æ‹¬ï¼š
- ç”Ÿäº§ç¯å¢ƒé…ç½®ç®¡ç†
- ç›‘æ§æŒ‡æ ‡æ”¶é›†
- å¥åº·æ£€æŸ¥å®ç°
- å®‰å…¨é…ç½®
- æ€§èƒ½ä¼˜åŒ–
- å®¹å™¨åŒ–éƒ¨ç½²

## è¿è¡Œç¤ºä¾‹

```bash
# å¼€å‘ç¯å¢ƒè¿è¡Œ
cargo run --example chapter16_production_deployment

# ç”Ÿäº§ç¯å¢ƒæ„å»º
cargo build --release --example chapter16_production_deployment

# Docker æ„å»º
docker build -t kzg-production-service:latest .

# Kubernetes éƒ¨ç½²
kubectl apply -f deployment/kubernetes/
```

## åŠŸèƒ½ç‰¹æ€§

- âœ… é«˜æ€§èƒ½ HTTP API æœåŠ¡
- âœ… Prometheus ç›‘æ§æŒ‡æ ‡
- âœ… ç»“æ„åŒ–æ—¥å¿—è®°å½•
- âœ… å¥åº·æ£€æŸ¥ç«¯ç‚¹
- âœ… é…ç½®çƒ­é‡è½½
- âœ… ä¼˜é›…å…³é—­å¤„ç†
- âœ… é€Ÿç‡é™åˆ¶
- âœ… å®‰å…¨ä¸­é—´ä»¶
- âœ… é”™è¯¯å¤„ç†å’Œæ¢å¤
- âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•
*/

use std::sync::Arc;
use std::time::{Duration, Instant};
use std::collections::HashMap;

use tokio::{signal, fs};
use tokio::sync::{RwLock, Mutex};
use axum::{
    Router, 
    routing::{get, post},
    extract::{State, Query, Json, Path},
    response::{IntoResponse, Response},
    http::{StatusCode, HeaderMap},
    middleware,
};
use tower::{ServiceBuilder, timeout::TimeoutLayer};
use tower_http::{
    cors::CorsLayer,
    trace::TraceLayer,
    compression::CompressionLayer,
    limit::RequestBodyLimitLayer,
};
use serde::{Deserialize, Serialize};
use prometheus::{
    Counter, Histogram, Gauge, Registry,
    IntCounter, IntGauge, HistogramVec,
    register_counter, register_histogram, register_gauge,
    register_int_counter, register_int_gauge, register_histogram_vec,
};
use tracing::{info, warn, error, debug, Level};
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};
use anyhow::{Result, Context};
use thiserror::Error;

// KZG ç›¸å…³å¯¼å…¥
use kzg::{
    G1,
    eip_4844::{
        blob_to_kzg_commitment_rust,
        compute_blob_kzg_proof_rust, 
        verify_blob_kzg_proof_rust,
        bytes_to_blob,
        BYTES_PER_BLOB,
    },
};
use rust_kzg_blst::{
    types::{g1::FsG1, kzg_settings::FsKZGSettings},
    eip_4844::load_trusted_setup_filename_rust,
};

// ================================================================================================
// æ ¸å¿ƒæœåŠ¡ç»“æ„
// ================================================================================================

/// ç”Ÿäº§ç¯å¢ƒ KZG æœåŠ¡ä¸»ç»“æ„
#[derive(Clone)]
pub struct ProductionKzgService {
    /// KZG è®¾ç½®
    kzg_settings: Arc<FsKZGSettings>,
    
    /// é…ç½®ç®¡ç†
    config: Arc<RwLock<ProductionConfig>>,
    
    /// ç›‘æ§æŒ‡æ ‡
    metrics: Arc<KzgMetrics>,
    
    /// å¥åº·æ£€æŸ¥å™¨
    health_checker: Arc<HealthChecker>,
    
    /// é€Ÿç‡é™åˆ¶å™¨
    rate_limiter: Arc<RateLimiter>,
    
    /// å®‰å…¨ç®¡ç†å™¨
    security_manager: Arc<SecurityManager>,
    
    /// ç¼“å­˜ç®¡ç†å™¨
    cache_manager: Arc<CacheManager>,
}

// ================================================================================================
// é…ç½®ç®¡ç†
// ================================================================================================

/// ç”Ÿäº§ç¯å¢ƒé…ç½®
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct ProductionConfig {
    pub server: ServerConfig,
    pub kzg: KzgConfig,
    pub monitoring: MonitoringConfig,
    pub security: SecurityConfig,
    pub performance: PerformanceConfig,
    pub logging: LoggingConfig,
}

#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct ServerConfig {
    pub host: String,
    pub port: u16,
    pub workers: Option<usize>,
    pub max_connections: u32,
    pub request_timeout_seconds: u64,
    pub keep_alive_seconds: u64,
    pub graceful_shutdown_timeout_seconds: u64,
}

#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct KzgConfig {
    pub trusted_setup_path: String,
    pub max_blob_size: usize,
    pub enable_parallel: bool,
    pub thread_pool_size: Option<usize>,
}

#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct MonitoringConfig {
    pub enabled: bool,
    pub prometheus_port: u16,
    pub metrics_path: String,
    pub collection_interval_seconds: u64,
    pub retention_days: u32,
}

#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct SecurityConfig {
    pub enable_tls: bool,
    pub cert_path: Option<String>,
    pub key_path: Option<String>,
    pub enable_auth: bool,
    pub api_keys: Vec<String>,
    pub rate_limit: RateLimitConfig,
    pub cors: CorsConfig,
}

#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct RateLimitConfig {
    pub requests_per_second: u64,
    pub burst_size: u64,
    pub enable_per_ip: bool,
    pub window_seconds: u64,
}

#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct CorsConfig {
    pub allow_origins: Vec<String>,
    pub allow_methods: Vec<String>,
    pub allow_headers: Vec<String>,
    pub expose_headers: Vec<String>,
    pub max_age_seconds: u64,
}

#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct PerformanceConfig {
    pub enable_caching: bool,
    pub cache_size: usize,
    pub cache_ttl_seconds: u64,
    pub batch_processing: bool,
    pub max_batch_size: usize,
}

#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct LoggingConfig {
    pub level: String,
    pub format: String, // "json" | "pretty"
    pub output: String, // "stdout" | "file"
    pub file_path: Option<String>,
    pub rotate_size_mb: u64,
    pub max_files: u32,
}

impl Default for ProductionConfig {
    fn default() -> Self {
        Self {
            server: ServerConfig {
                host: "0.0.0.0".to_string(),
                port: 8080,
                workers: None,
                max_connections: 10000,
                request_timeout_seconds: 30,
                keep_alive_seconds: 60,
                graceful_shutdown_timeout_seconds: 30,
            },
            kzg: KzgConfig {
                trusted_setup_path: "assets/trusted_setup.txt".to_string(),
                max_blob_size: 131072, // 128KB
                enable_parallel: true,
                thread_pool_size: None,
            },
            monitoring: MonitoringConfig {
                enabled: true,
                prometheus_port: 9090,
                metrics_path: "/metrics".to_string(),
                collection_interval_seconds: 15,
                retention_days: 30,
            },
            security: SecurityConfig {
                enable_tls: false,
                cert_path: None,
                key_path: None,
                enable_auth: false,
                api_keys: vec![],
                rate_limit: RateLimitConfig {
                    requests_per_second: 1000,
                    burst_size: 100,
                    enable_per_ip: true,
                    window_seconds: 60,
                },
                cors: CorsConfig {
                    allow_origins: vec!["*".to_string()],
                    allow_methods: vec!["GET".to_string(), "POST".to_string()],
                    allow_headers: vec!["Content-Type".to_string(), "Authorization".to_string()],
                    expose_headers: vec![],
                    max_age_seconds: 3600,
                },
            },
            performance: PerformanceConfig {
                enable_caching: true,
                cache_size: 1000,
                cache_ttl_seconds: 300,
                batch_processing: true,
                max_batch_size: 100,
            },
            logging: LoggingConfig {
                level: "info".to_string(),
                format: "json".to_string(),
                output: "stdout".to_string(),
                file_path: None,
                rotate_size_mb: 100,
                max_files: 10,
            },
        }
    }
}

// ================================================================================================
// ç›‘æ§æŒ‡æ ‡
// ================================================================================================

/// KZG æœåŠ¡ç›‘æ§æŒ‡æ ‡
pub struct KzgMetrics {
    // HTTP è¯·æ±‚æŒ‡æ ‡
    pub http_requests_total: IntCounter,
    pub http_request_duration: HistogramVec,
    pub http_requests_in_flight: IntGauge,
    
    // KZG ä¸šåŠ¡æŒ‡æ ‡
    pub kzg_commitments_total: IntCounter,
    pub kzg_proofs_total: IntCounter,
    pub kzg_verifications_total: IntCounter,
    pub kzg_das_operations_total: IntCounter,
    
    // æ€§èƒ½æŒ‡æ ‡
    pub commitment_duration: Histogram,
    pub proof_duration: Histogram,
    pub verification_duration: Histogram,
    pub das_duration: Histogram,
    
    // ç³»ç»ŸæŒ‡æ ‡
    pub memory_usage_bytes: Gauge,
    pub cpu_usage_percent: Gauge,
    pub active_connections: IntGauge,
    pub cache_hit_rate: Gauge,
    
    // é”™è¯¯æŒ‡æ ‡
    pub errors_total: IntCounter,
    pub timeouts_total: IntCounter,
    pub rate_limit_exceeded_total: IntCounter,
}

impl KzgMetrics {
    pub fn new() -> Result<Self> {
        Ok(Self {
            // HTTP æŒ‡æ ‡
            http_requests_total: register_int_counter!(
                "kzg_http_requests_total",
                "Total number of HTTP requests"
            )?,
            http_request_duration: register_histogram_vec!(
                "kzg_http_request_duration_seconds",
                "HTTP request duration in seconds",
                &["method", "endpoint", "status"]
            )?,
            http_requests_in_flight: register_int_gauge!(
                "kzg_http_requests_in_flight",
                "Number of HTTP requests currently being processed"
            )?,
            
            // KZG ä¸šåŠ¡æŒ‡æ ‡
            kzg_commitments_total: register_int_counter!(
                "kzg_commitments_total",
                "Total number of KZG commitments created"
            )?,
            kzg_proofs_total: register_int_counter!(
                "kzg_proofs_total",
                "Total number of KZG proofs generated"
            )?,
            kzg_verifications_total: register_int_counter!(
                "kzg_verifications_total",
                "Total number of KZG verifications performed"
            )?,
            kzg_das_operations_total: register_int_counter!(
                "kzg_das_operations_total",
                "Total number of DAS operations performed"
            )?,
            
            // æ€§èƒ½æŒ‡æ ‡
            commitment_duration: register_histogram!(
                "kzg_commitment_duration_seconds",
                "Time spent creating KZG commitments",
                vec![0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]
            )?,
            proof_duration: register_histogram!(
                "kzg_proof_duration_seconds",
                "Time spent generating KZG proofs",
                vec![0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0, 25.0, 50.0]
            )?,
            verification_duration: register_histogram!(
                "kzg_verification_duration_seconds", 
                "Time spent verifying KZG proofs",
                vec![0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]
            )?,
            das_duration: register_histogram!(
                "kzg_das_duration_seconds",
                "Time spent on DAS operations",
                vec![0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0, 25.0, 50.0, 100.0]
            )?,
            
            // ç³»ç»ŸæŒ‡æ ‡
            memory_usage_bytes: register_gauge!(
                "kzg_memory_usage_bytes",
                "Memory usage in bytes"
            )?,
            cpu_usage_percent: register_gauge!(
                "kzg_cpu_usage_percent",
                "CPU usage percentage"
            )?,
            active_connections: register_int_gauge!(
                "kzg_active_connections",
                "Number of active connections"
            )?,
            cache_hit_rate: register_gauge!(
                "kzg_cache_hit_rate",
                "Cache hit rate (0.0 to 1.0)"
            )?,
            
            // é”™è¯¯æŒ‡æ ‡
            errors_total: register_int_counter!(
                "kzg_errors_total",
                "Total number of errors"
            )?,
            timeouts_total: register_int_counter!(
                "kzg_timeouts_total",
                "Total number of timeouts"
            )?,
            rate_limit_exceeded_total: register_int_counter!(
                "kzg_rate_limit_exceeded_total",
                "Total number of rate limit exceeded events"
            )?,
        })
    }
}

// ================================================================================================
// å¥åº·æ£€æŸ¥
// ================================================================================================

/// å¥åº·æ£€æŸ¥å™¨
pub struct HealthChecker {
    kzg_health: Arc<Mutex<bool>>,
    system_health: Arc<Mutex<SystemHealth>>,
    external_dependencies: Arc<Mutex<HashMap<String, bool>>>,
}

#[derive(Debug, Clone, Serialize)]
pub struct SystemHealth {
    pub memory_usage: f64,
    pub cpu_usage: f64,
    pub disk_usage: f64,
    pub network_connectivity: bool,
}

#[derive(Serialize)]
pub struct HealthStatus {
    pub status: String,
    pub timestamp: u64,
    pub services: HashMap<String, ServiceStatus>,
    pub system: SystemHealth,
}

#[derive(Serialize)]
pub struct ServiceStatus {
    pub healthy: bool,
    pub last_check: u64,
    pub error_message: Option<String>,
}

impl HealthChecker {
    pub fn new() -> Self {
        Self {
            kzg_health: Arc::new(Mutex::new(true)),
            system_health: Arc::new(Mutex::new(SystemHealth {
                memory_usage: 0.0,
                cpu_usage: 0.0,
                disk_usage: 0.0,
                network_connectivity: true,
            })),
            external_dependencies: Arc::new(Mutex::new(HashMap::new())),
        }
    }
    
    /// æ‰§è¡Œå¥åº·æ£€æŸ¥
    pub async fn check_health(&self) -> HealthStatus {
        let mut services = HashMap::new();
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs();
        
        // KZG æœåŠ¡å¥åº·æ£€æŸ¥
        let kzg_healthy = *self.kzg_health.lock().await;
        services.insert("kzg".to_string(), ServiceStatus {
            healthy: kzg_healthy,
            last_check: timestamp,
            error_message: if kzg_healthy { None } else { Some("KZG service unhealthy".to_string()) },
        });
        
        // å¤–éƒ¨ä¾èµ–å¥åº·æ£€æŸ¥
        let deps = self.external_dependencies.lock().await;
        for (name, healthy) in deps.iter() {
            services.insert(name.clone(), ServiceStatus {
                healthy: *healthy,
                last_check: timestamp,
                error_message: if *healthy { None } else { Some(format!("{} service unhealthy", name)) },
            });
        }
        
        // ç³»ç»Ÿå¥åº·çŠ¶æ€
        let system = self.system_health.lock().await.clone();
        
        // æ•´ä½“çŠ¶æ€åˆ¤æ–­
        let overall_healthy = services.values().all(|s| s.healthy) 
            && system.memory_usage < 90.0
            && system.cpu_usage < 90.0
            && system.disk_usage < 90.0;
        
        HealthStatus {
            status: if overall_healthy { "healthy".to_string() } else { "unhealthy".to_string() },
            timestamp,
            services,
            system,
        }
    }
    
    /// æ£€æŸ¥å°±ç»ªçŠ¶æ€
    pub async fn check_readiness(&self) -> bool {
        let kzg_healthy = *self.kzg_health.lock().await;
        let system = self.system_health.lock().await;
        
        kzg_healthy && system.network_connectivity
    }
    
    /// æ‰§è¡Œæ´»è·ƒæ£€æŸ¥
    pub async fn check_liveness(&self) -> bool {
        // ç®€å•çš„æ´»è·ƒæ£€æŸ¥ - æœåŠ¡æ˜¯å¦å“åº”
        true
    }
}

// ================================================================================================
// é€Ÿç‡é™åˆ¶å™¨
// ================================================================================================

use std::sync::atomic::{AtomicU64, Ordering};
use std::num::NonZeroUsize;
use std::collections::VecDeque;

/// åŸºäºä»¤ç‰Œæ¡¶ç®—æ³•çš„é€Ÿç‡é™åˆ¶å™¨
pub struct RateLimiter {
    capacity: u64,
    tokens: AtomicU64,
    refill_rate: u64,
    last_refill: AtomicU64,
    per_ip_limiters: Arc<Mutex<HashMap<String, IpRateLimiter>>>,
}

struct IpRateLimiter {
    requests: VecDeque<u64>,
    window_seconds: u64,
    max_requests: u64,
}

impl RateLimiter {
    pub fn new(requests_per_second: u64, burst_size: u64) -> Self {
        Self {
            capacity: burst_size,
            tokens: AtomicU64::new(burst_size),
            refill_rate: requests_per_second,
            last_refill: AtomicU64::new(
                std::time::SystemTime::now()
                    .duration_since(std::time::UNIX_EPOCH)
                    .unwrap()
                    .as_secs()
            ),
            per_ip_limiters: Arc::new(Mutex::new(HashMap::new())),
        }
    }
    
    /// æ£€æŸ¥æ˜¯å¦å…è®¸è¯·æ±‚
    pub async fn check_rate_limit(&self, client_ip: Option<&str>) -> Result<(), RateLimitError> {
        // å…¨å±€é€Ÿç‡é™åˆ¶
        if !self.consume_token() {
            return Err(RateLimitError::GlobalLimitExceeded);
        }
        
        // IP çº§åˆ«é€Ÿç‡é™åˆ¶
        if let Some(ip) = client_ip {
            if !self.check_ip_rate_limit(ip).await {
                return Err(RateLimitError::IpLimitExceeded);
            }
        }
        
        Ok(())
    }
    
    fn consume_token(&self) -> bool {
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs();
        
        // è¡¥å……ä»¤ç‰Œ
        let last_refill = self.last_refill.load(Ordering::Relaxed);
        if now > last_refill {
            let time_passed = now - last_refill;
            let tokens_to_add = time_passed * self.refill_rate;
            let current_tokens = self.tokens.load(Ordering::Relaxed);
            let new_tokens = std::cmp::min(current_tokens + tokens_to_add, self.capacity);
            
            self.tokens.store(new_tokens, Ordering::Relaxed);
            self.last_refill.store(now, Ordering::Relaxed);
        }
        
        // å°è¯•æ¶ˆè´¹ä»¤ç‰Œ
        loop {
            let current_tokens = self.tokens.load(Ordering::Relaxed);
            if current_tokens == 0 {
                return false;
            }
            
            let new_tokens = current_tokens - 1;
            if self.tokens.compare_exchange_weak(
                current_tokens, 
                new_tokens, 
                Ordering::Relaxed, 
                Ordering::Relaxed
            ).is_ok() {
                return true;
            }
        }
    }
    
    async fn check_ip_rate_limit(&self, ip: &str) -> bool {
        let mut limiters = self.per_ip_limiters.lock().await;
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs();
        
        let limiter = limiters.entry(ip.to_string())
            .or_insert(IpRateLimiter {
                requests: VecDeque::new(),
                window_seconds: 60,
                max_requests: 100,
            });
        
        // æ¸…ç†è¿‡æœŸè¯·æ±‚
        while let Some(&front) = limiter.requests.front() {
            if now - front > limiter.window_seconds {
                limiter.requests.pop_front();
            } else {
                break;
            }
        }
        
        // æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        if limiter.requests.len() >= limiter.max_requests as usize {
            false
        } else {
            limiter.requests.push_back(now);
            true
        }
    }
}

#[derive(Debug, Error)]
pub enum RateLimitError {
    #[error("Global rate limit exceeded")]
    GlobalLimitExceeded,
    
    #[error("IP rate limit exceeded")]
    IpLimitExceeded,
}

// ================================================================================================
// å®‰å…¨ç®¡ç†å™¨
// ================================================================================================

/// å®‰å…¨ç®¡ç†å™¨
pub struct SecurityManager {
    api_keys: Arc<RwLock<Vec<String>>>,
    blocked_ips: Arc<RwLock<HashSet<String>>>,
}

impl SecurityManager {
    pub fn new(api_keys: Vec<String>) -> Self {
        Self {
            api_keys: Arc::new(RwLock::new(api_keys)),
            blocked_ips: Arc::new(RwLock::new(HashSet::new())),
        }
    }
    
    /// éªŒè¯ API å¯†é’¥
    pub async fn validate_api_key(&self, key: &str) -> bool {
        let keys = self.api_keys.read().await;
        keys.contains(&key.to_string())
    }
    
    /// æ£€æŸ¥ IP æ˜¯å¦è¢«é˜»æ­¢
    pub async fn is_ip_blocked(&self, ip: &str) -> bool {
        let blocked = self.blocked_ips.read().await;
        blocked.contains(ip)
    }
    
    /// é˜»æ­¢ IP åœ°å€
    pub async fn block_ip(&self, ip: &str) {
        let mut blocked = self.blocked_ips.write().await;
        blocked.insert(ip.to_string());
    }
}

use std::collections::HashSet;

// ================================================================================================
// ç¼“å­˜ç®¡ç†å™¨
// ================================================================================================

/// ç®€å•çš„ LRU ç¼“å­˜ç®¡ç†å™¨
pub struct CacheManager {
    cache: Arc<Mutex<lru::LruCache<String, CacheEntry>>>,
    ttl_seconds: u64,
}

#[derive(Clone)]
struct CacheEntry {
    data: Vec<u8>,
    created_at: u64,
}

impl CacheManager {
    pub fn new(capacity: usize, ttl_seconds: u64) -> Self {
        Self {
            cache: Arc::new(Mutex::new(lru::LruCache::new(
                NonZeroUsize::new(capacity).unwrap()
            ))),
            ttl_seconds,
        }
    }
    
    /// è·å–ç¼“å­˜é¡¹
    pub async fn get(&self, key: &str) -> Option<Vec<u8>> {
        let mut cache = self.cache.lock().await;
        if let Some(entry) = cache.get(key) {
            let now = std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs();
                
            if now - entry.created_at < self.ttl_seconds {
                Some(entry.data.clone())
            } else {
                cache.pop(key);
                None
            }
        } else {
            None
        }
    }
    
    /// è®¾ç½®ç¼“å­˜é¡¹
    pub async fn set(&self, key: String, data: Vec<u8>) {
        let mut cache = self.cache.lock().await;
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs();
            
        cache.put(key, CacheEntry {
            data,
            created_at: now,
        });
    }
}

// ================================================================================================
// API è¯·æ±‚å’Œå“åº”ç»“æ„
// ================================================================================================

#[derive(Debug, Deserialize)]
pub struct CommitmentRequest {
    pub blob: String, // hex encoded blob
}

#[derive(Debug, Serialize)]
pub struct CommitmentResponse {
    pub commitment: String, // hex encoded commitment
    pub processing_time_ms: u64,
}

#[derive(Debug, Deserialize)]
pub struct ProofRequest {
    pub blob: String,
    pub commitment: String,
}

#[derive(Debug, Serialize)]
pub struct ProofResponse {
    pub proof: String,
    pub processing_time_ms: u64,
}

#[derive(Debug, Deserialize)]
pub struct VerificationRequest {
    pub blob: String,
    pub commitment: String,
    pub proof: String,
}

#[derive(Debug, Serialize)]
pub struct VerificationResponse {
    pub is_valid: bool,
    pub processing_time_ms: u64,
}

#[derive(Debug, Deserialize)]
pub struct BatchRequest {
    pub requests: Vec<BatchItem>,
}

#[derive(Debug, Deserialize)]
pub struct BatchItem {
    pub id: String,
    pub operation: String, // "commitment" | "proof" | "verification"
    pub blob: String,
    pub commitment: Option<String>,
    pub proof: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct BatchResponse {
    pub results: Vec<BatchResult>,
    pub total_processing_time_ms: u64,
}

#[derive(Debug, Serialize)]
pub struct BatchResult {
    pub id: String,
    pub success: bool,
    pub result: Option<serde_json::Value>,
    pub error: Option<String>,
}

// ================================================================================================
// é”™è¯¯å¤„ç†
// ================================================================================================

#[derive(Debug, Error)]
pub enum ServiceError {
    #[error("Invalid blob size: expected {expected}, got {actual}")]
    InvalidBlobSize { expected: usize, actual: usize },
    
    #[error("Invalid hex encoding: {0}")]
    InvalidHexEncoding(String),
    
    #[error("KZG operation failed: {0}")]
    KzgError(String),
    
    #[error("Rate limit exceeded")]
    RateLimitExceeded,
    
    #[error("Unauthorized")]
    Unauthorized,
    
    #[error("Internal server error: {0}")]
    InternalError(String),
    
    #[error("Service unavailable")]
    ServiceUnavailable,
    
    #[error("Request timeout")]
    Timeout,
}

impl IntoResponse for ServiceError {
    fn into_response(self) -> Response {
        let (status, error_message) = match self {
            ServiceError::InvalidBlobSize { .. } | 
            ServiceError::InvalidHexEncoding(_) => (StatusCode::BAD_REQUEST, self.to_string()),
            ServiceError::RateLimitExceeded => (StatusCode::TOO_MANY_REQUESTS, self.to_string()),
            ServiceError::Unauthorized => (StatusCode::UNAUTHORIZED, self.to_string()),
            ServiceError::ServiceUnavailable => (StatusCode::SERVICE_UNAVAILABLE, self.to_string()),
            ServiceError::Timeout => (StatusCode::REQUEST_TIMEOUT, self.to_string()),
            _ => (StatusCode::INTERNAL_SERVER_ERROR, "Internal server error".to_string()),
        };
        
        let body = serde_json::json!({
            "error": error_message,
            "timestamp": std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs()
        });
        
        (status, Json(body)).into_response()
    }
}

// ================================================================================================
// å®ç°æ ¸å¿ƒæœåŠ¡
// ================================================================================================

impl ProductionKzgService {
    /// åˆ›å»ºæ–°çš„ç”Ÿäº§ KZG æœåŠ¡å®ä¾‹
    pub async fn new(config: ProductionConfig) -> Result<Self> {
        // åˆå§‹åŒ–æ—¥å¿—
        Self::init_logging(&config.logging)?;
        
        info!("Initializing Production KZG Service...");
        
        // åŠ è½½ KZG è®¾ç½®
        info!("Loading trusted setup from: {}", config.kzg.trusted_setup_path);
        let kzg_settings = Arc::new(
            load_trusted_setup_filename_rust(&config.kzg.trusted_setup_path)
                .map_err(|e| anyhow::anyhow!("Failed to load trusted setup: {}", e))?
        );
        info!("Successfully loaded KZG settings");
        
        // åˆå§‹åŒ–ç›‘æ§æŒ‡æ ‡
        let metrics = Arc::new(KzgMetrics::new()
            .map_err(|e| anyhow::anyhow!("Failed to initialize metrics: {}", e))?);
        
        info!("Initialized monitoring metrics");
        
        // åˆå§‹åŒ–å¥åº·æ£€æŸ¥å™¨
        let health_checker = Arc::new(HealthChecker::new());
        info!("Initialized health checker");
        
        // åˆå§‹åŒ–é€Ÿç‡é™åˆ¶å™¨
        let rate_limiter = Arc::new(RateLimiter::new(
            config.security.rate_limit.requests_per_second,
            config.security.rate_limit.burst_size,
        ));
        info!("Initialized rate limiter");
        
        // åˆå§‹åŒ–å®‰å…¨ç®¡ç†å™¨
        let security_manager = Arc::new(SecurityManager::new(
            config.security.api_keys.clone()
        ));
        info!("Initialized security manager");
        
        // åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        let cache_manager = Arc::new(CacheManager::new(
            config.performance.cache_size,
            config.performance.cache_ttl_seconds,
        ));
        info!("Initialized cache manager");
        
        info!("Production KZG Service initialized successfully");
        
        Ok(Self {
            kzg_settings,
            config: Arc::new(RwLock::new(config)),
            metrics,
            health_checker,
            rate_limiter,
            security_manager,
            cache_manager,
        })
    }
    
    fn init_logging(config: &LoggingConfig) -> Result<()> {
        let level = match config.level.as_str() {
            "trace" => Level::TRACE,
            "debug" => Level::DEBUG,
            "info" => Level::INFO,
            "warn" => Level::WARN,
            "error" => Level::ERROR,
            _ => Level::INFO,
        };
        
        match config.format.as_str() {
            "json" => {
                tracing_subscriber::registry()
                    .with(
                        tracing_subscriber::fmt::layer()
                            .json()
                            .with_level(true)
                            .with_target(true)
                            .with_thread_ids(true)
                            .with_file(true)
                            .with_line_number(true)
                    )
                    .with(tracing_subscriber::filter::LevelFilter::from_level(level))
                    .init();
            },
            _ => {
                tracing_subscriber::registry()
                    .with(
                        tracing_subscriber::fmt::layer()
                            .pretty()
                            .with_level(true)
                            .with_target(false)
                    )
                    .with(tracing_subscriber::filter::LevelFilter::from_level(level))
                    .init();
            }
        }
        
        Ok(())
    }
    
    /// åˆ›å»ºæ‰¿è¯º
    pub async fn create_commitment(&self, request: CommitmentRequest) -> Result<CommitmentResponse, ServiceError> {
        let start = Instant::now();
        
        // è®°å½•æŒ‡æ ‡
        self.metrics.http_requests_total.inc();
        self.metrics.kzg_commitments_total.inc();
        
        // æ£€æŸ¥ç¼“å­˜
        let cache_key = format!("commitment:{}", request.blob);
        if let Some(cached) = self.cache_manager.get(&cache_key).await {
            let commitment = hex::encode(cached);
            return Ok(CommitmentResponse {
                commitment,
                processing_time_ms: start.elapsed().as_millis() as u64,
            });
        }
        
        // è§£ç  blob
        let blob_bytes = hex::decode(&request.blob)
            .map_err(|e| ServiceError::InvalidHexEncoding(e.to_string()))?;
        
        if blob_bytes.len() != BYTES_PER_BLOB {
            return Err(ServiceError::InvalidBlobSize {
                expected: BYTES_PER_BLOB,
                actual: blob_bytes.len(),
            });
        }
        
        // è½¬æ¢ä¸º Fr æ•°ç»„
        let blob_fr = bytes_to_blob(&blob_bytes)
            .map_err(|e| ServiceError::KzgError(e.to_string()))?;
        
        // ç”Ÿæˆæ‰¿è¯º
        let commitment = blob_to_kzg_commitment_rust(&blob_fr, &*self.kzg_settings)
            .map_err(|e| ServiceError::KzgError(e.to_string()))?;
        
        let commitment_bytes = commitment.to_bytes();
        let commitment_hex = hex::encode(&commitment_bytes);
        
        // ç¼“å­˜ç»“æœ
        self.cache_manager.set(cache_key, commitment_bytes.to_vec()).await;
        
        // è®°å½•æ€§èƒ½æŒ‡æ ‡
        self.metrics.commitment_duration.observe(start.elapsed().as_secs_f64());
        
        Ok(CommitmentResponse {
            commitment: commitment_hex,
            processing_time_ms: start.elapsed().as_millis() as u64,
        })
    }
    
    /// ç”Ÿæˆè¯æ˜
    pub async fn generate_proof(&self, request: ProofRequest) -> Result<ProofResponse, ServiceError> {
        let start = Instant::now();
        
        // è®°å½•æŒ‡æ ‡
        self.metrics.kzg_proofs_total.inc();
        
        // è§£ç è¾“å…¥
        let blob_bytes = hex::decode(&request.blob)
            .map_err(|e| ServiceError::InvalidHexEncoding(e.to_string()))?;
        let commitment_bytes = hex::decode(&request.commitment)
            .map_err(|e| ServiceError::InvalidHexEncoding(e.to_string()))?;
        
        // éªŒè¯å¤§å°
        if blob_bytes.len() != BYTES_PER_BLOB {
            return Err(ServiceError::InvalidBlobSize {
                expected: BYTES_PER_BLOB,
                actual: blob_bytes.len(),
            });
        }
        
        // è½¬æ¢æ•°æ®
        let blob_fr = bytes_to_blob(&blob_bytes)
            .map_err(|e| ServiceError::KzgError(e.to_string()))?;
        
        let commitment = FsG1::from_bytes(&commitment_bytes)
            .map_err(|e| ServiceError::KzgError(e.to_string()))?;
        
        // ç”Ÿæˆè¯æ˜
        let proof = compute_blob_kzg_proof_rust(&blob_fr, &commitment, &*self.kzg_settings)
            .map_err(|e| ServiceError::KzgError(e.to_string()))?;
        
        let proof_bytes = proof.to_bytes();
        let proof_hex = hex::encode(&proof_bytes);
        
        // è®°å½•æ€§èƒ½æŒ‡æ ‡
        self.metrics.proof_duration.observe(start.elapsed().as_secs_f64());
        
        Ok(ProofResponse {
            proof: proof_hex,
            processing_time_ms: start.elapsed().as_millis() as u64,
        })
    }
    
    /// éªŒè¯è¯æ˜
    pub async fn verify_proof(&self, request: VerificationRequest) -> Result<VerificationResponse, ServiceError> {
        let start = Instant::now();
        
        // è®°å½•æŒ‡æ ‡
        self.metrics.kzg_verifications_total.inc();
        
        // è§£ç è¾“å…¥
        let blob_bytes = hex::decode(&request.blob)
            .map_err(|e| ServiceError::InvalidHexEncoding(e.to_string()))?;
        let commitment_bytes = hex::decode(&request.commitment)
            .map_err(|e| ServiceError::InvalidHexEncoding(e.to_string()))?;
        let proof_bytes = hex::decode(&request.proof)
            .map_err(|e| ServiceError::InvalidHexEncoding(e.to_string()))?;
        
        // è½¬æ¢æ•°æ®
        let blob_fr = bytes_to_blob(&blob_bytes)
            .map_err(|e| ServiceError::KzgError(e.to_string()))?;
        
        let commitment = FsG1::from_bytes(&commitment_bytes)
            .map_err(|e| ServiceError::KzgError(e.to_string()))?;
        
        let proof = FsG1::from_bytes(&proof_bytes)
            .map_err(|e| ServiceError::KzgError(e.to_string()))?;
        
        // éªŒè¯è¯æ˜
        let is_valid = verify_blob_kzg_proof_rust(
            &blob_fr,
            &commitment,
            &proof,
            &*self.kzg_settings
        ).map_err(|e| ServiceError::KzgError(e.to_string()))?;
        
        // è®°å½•æ€§èƒ½æŒ‡æ ‡
        self.metrics.verification_duration.observe(start.elapsed().as_secs_f64());
        
        Ok(VerificationResponse {
            is_valid,
            processing_time_ms: start.elapsed().as_millis() as u64,
        })
    }
}

// ================================================================================================
// HTTP æœåŠ¡å™¨å’Œ API ç«¯ç‚¹
// ================================================================================================

/// HTTP æœåŠ¡å™¨å¯åŠ¨ - ç®€åŒ–ç‰ˆæœ¬
pub async fn start_http_server(service: ProductionKzgService) -> Result<()> {
    let config = service.config.read().await;
    let addr = format!("{}:{}", config.server.host, config.server.port);
    
    info!("å¯åŠ¨ HTTP æœåŠ¡å™¨: {}", addr);
    
    // æ„å»ºç®€åŒ–çš„åº”ç”¨è·¯ç”±
    let app = create_simple_router(service.clone()).await;
    
    info!("HTTP æœåŠ¡å™¨å·²å¯åŠ¨ï¼Œç›‘å¬åœ°å€: {}", addr);
    
    // ä½¿ç”¨ç®€åŒ–çš„æœåŠ¡å™¨å¯åŠ¨æ–¹å¼
    axum::Server::bind(&addr.parse()?)
        .serve(app.into_make_service())
        .with_graceful_shutdown(shutdown_signal())
        .await
        .context("HTTP server error")?;
        
    info!("HTTP æœåŠ¡å™¨å·²å…³é—­");
    Ok(())
}

/// åˆ›å»ºç®€åŒ–çš„åº”ç”¨è·¯ç”±
async fn create_simple_router(service: ProductionKzgService) -> Router {
    Router::new()
        // API è·¯ç”±
        .route("/api/v1/commitment", post(create_commitment_handler))
        .route("/api/v1/proof", post(generate_proof_handler))
        .route("/api/v1/verify", post(verify_proof_handler))
        .route("/api/v1/batch", post(batch_process_handler))
        
        // å¥åº·æ£€æŸ¥è·¯ç”±
        .route("/health", get(health_handler))
        .route("/health/live", get(liveness_handler))
        .route("/health/ready", get(readiness_handler))
        
        // ç›‘æ§è·¯ç”±
        .route("/metrics", get(metrics_handler))
        
        // ç®¡ç†è·¯ç”±
        .route("/admin/config", get(get_config_handler))
        .route("/admin/stats", get(get_stats_handler))
        
        .with_state(service)
}

// ================================================================================================
// API å¤„ç†å™¨
// ================================================================================================

/// åˆ›å»ºæ‰¿è¯ºå¤„ç†å™¨
async fn create_commitment_handler(
    State(service): State<ProductionKzgService>,
    Json(request): Json<CommitmentRequest>
) -> Result<Json<CommitmentResponse>, ServiceError> {
    let response = service.create_commitment(request).await?;
    Ok(Json(response))
}

/// ç”Ÿæˆè¯æ˜å¤„ç†å™¨
async fn generate_proof_handler(
    State(service): State<ProductionKzgService>,
    Json(request): Json<ProofRequest>
) -> Result<Json<ProofResponse>, ServiceError> {
    let response = service.generate_proof(request).await?;
    Ok(Json(response))
}

/// éªŒè¯è¯æ˜å¤„ç†å™¨
async fn verify_proof_handler(
    State(service): State<ProductionKzgService>,
    Json(request): Json<VerificationRequest>
) -> Result<Json<VerificationResponse>, ServiceError> {
    let response = service.verify_proof(request).await?;
    Ok(Json(response))
}

/// æ‰¹é‡å¤„ç†å¤„ç†å™¨
async fn batch_process_handler(
    State(service): State<ProductionKzgService>,
    Json(request): Json<BatchRequest>
) -> Result<Json<BatchResponse>, ServiceError> {
    let start = Instant::now();
    
    let mut results = Vec::new();
    
    for item in request.requests {
        let result = match item.operation.as_str() {
            "commitment" => {
                match service.create_commitment(CommitmentRequest {
                    blob: item.blob.clone()
                }).await {
                    Ok(response) => BatchResult {
                        id: item.id,
                        success: true,
                        result: Some(serde_json::to_value(response).unwrap()),
                        error: None,
                    },
                    Err(e) => BatchResult {
                        id: item.id,
                        success: false,
                        result: None,
                        error: Some(e.to_string()),
                    }
                }
            },
            "proof" => {
                if let Some(commitment) = item.commitment {
                    match service.generate_proof(ProofRequest {
                        blob: item.blob.clone(),
                        commitment,
                    }).await {
                        Ok(response) => BatchResult {
                            id: item.id,
                            success: true,
                            result: Some(serde_json::to_value(response).unwrap()),
                            error: None,
                        },
                        Err(e) => BatchResult {
                            id: item.id,
                            success: false,
                            result: None,
                            error: Some(e.to_string()),
                        }
                    }
                } else {
                    BatchResult {
                        id: item.id,
                        success: false,
                        result: None,
                        error: Some("Missing commitment for proof operation".to_string()),
                    }
                }
            },
            "verification" => {
                if let (Some(commitment), Some(proof)) = (item.commitment, item.proof) {
                    match service.verify_proof(VerificationRequest {
                        blob: item.blob.clone(),
                        commitment,
                        proof,
                    }).await {
                        Ok(response) => BatchResult {
                            id: item.id,
                            success: true,
                            result: Some(serde_json::to_value(response).unwrap()),
                            error: None,
                        },
                        Err(e) => BatchResult {
                            id: item.id,
                            success: false,
                            result: None,
                            error: Some(e.to_string()),
                        }
                    }
                } else {
                    BatchResult {
                        id: item.id,
                        success: false,
                        result: None,
                        error: Some("Missing commitment or proof for verification".to_string()),
                    }
                }
            },
            _ => BatchResult {
                id: item.id,
                success: false,
                result: None,
                error: Some(format!("Unknown operation: {}", item.operation)),
            }
        };
        
        results.push(result);
    }
    
    Ok(Json(BatchResponse {
        results,
        total_processing_time_ms: start.elapsed().as_millis() as u64,
    }))
}

// ================================================================================================
// å¥åº·æ£€æŸ¥å¤„ç†å™¨
// ================================================================================================

/// æ€»ä½“å¥åº·æ£€æŸ¥
async fn health_handler(
    State(service): State<ProductionKzgService>
) -> Json<HealthStatus> {
    Json(service.health_checker.check_health().await)
}

/// æ´»è·ƒæ€§æ£€æŸ¥
async fn liveness_handler(
    State(service): State<ProductionKzgService>
) -> impl IntoResponse {
    if service.health_checker.check_liveness().await {
        StatusCode::OK
    } else {
        StatusCode::SERVICE_UNAVAILABLE
    }
}

/// å°±ç»ªæ€§æ£€æŸ¥  
async fn readiness_handler(
    State(service): State<ProductionKzgService>
) -> impl IntoResponse {
    if service.health_checker.check_readiness().await {
        StatusCode::OK
    } else {
        StatusCode::SERVICE_UNAVAILABLE
    }
}

// ================================================================================================
// ç›‘æ§å¤„ç†å™¨
// ================================================================================================

/// Prometheus æŒ‡æ ‡ç«¯ç‚¹
async fn metrics_handler() -> impl IntoResponse {
    let encoder = prometheus::TextEncoder::new();
    let metric_families = prometheus::gather();
    
    match encoder.encode_to_string(&metric_families) {
        Ok(output) => {
            (
                StatusCode::OK,
                [("content-type", "text/plain; version=0.0.4")],
                output
            )
        }
        Err(_) => {
            (
                StatusCode::INTERNAL_SERVER_ERROR,
                [("content-type", "text/plain")],
                "Failed to encode metrics".to_string()
            )
        }
    }
}

// ================================================================================================
// ç®¡ç†å¤„ç†å™¨
// ================================================================================================

/// è·å–é…ç½®ä¿¡æ¯
async fn get_config_handler(
    State(service): State<ProductionKzgService>
) -> Json<serde_json::Value> {
    let config = service.config.read().await;
    
    // è¿”å›å®‰å…¨çš„é…ç½®ä¿¡æ¯ (éšè—æ•æ„Ÿä¿¡æ¯)
    let safe_config = serde_json::json!({
        "server": {
            "host": config.server.host,
            "port": config.server.port,
            "max_connections": config.server.max_connections,
        },
        "monitoring": config.monitoring,
        "performance": config.performance,
    });
    
    Json(safe_config)
}

/// è·å–ç»Ÿè®¡ä¿¡æ¯
async fn get_stats_handler(
    State(service): State<ProductionKzgService>
) -> Json<serde_json::Value> {
    let stats = serde_json::json!({
        "uptime_seconds": std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs(),
        "memory_usage": get_memory_usage(),
        "active_connections": service.metrics.active_connections.get(),
        "total_requests": service.metrics.http_requests_total.get(),
        "cache_stats": {
            "hit_rate": service.metrics.cache_hit_rate.get(),
        }
    });
    
    Json(stats)
}

fn get_memory_usage() -> u64 {
    // ç®€åŒ–çš„å†…å­˜ä½¿ç”¨ç»Ÿè®¡
    0
}

// ================================================================================================
// ä¼˜é›…å…³é—­
// ================================================================================================

/// ä¼˜é›…å…³é—­ä¿¡å·å¤„ç†
async fn shutdown_signal() {
    let ctrl_c = async {
        signal::ctrl_c()
            .await
            .expect("failed to install Ctrl+C handler");
    };

    #[cfg(unix)]
    let terminate = async {
        signal::unix::signal(signal::unix::SignalKind::terminate())
            .expect("failed to install signal handler")
            .recv()
            .await;
    };

    #[cfg(not(unix))]
    let terminate = std::future::pending::<()>();

    tokio::select! {
        _ = ctrl_c => {
            info!("æ”¶åˆ° Ctrl+C ä¿¡å·ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...");
        },
        _ = terminate => {
            info!("æ”¶åˆ° SIGTERM ä¿¡å·ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...");
        },
    }
}

// ================================================================================================
// ä¸»å‡½æ•°æ›´æ–°
// ================================================================================================

#[tokio::main]
async fn main() -> Result<()> {
    // åŠ è½½é…ç½®
    let config = load_config().await?;
    
    // åˆå§‹åŒ–æœåŠ¡
    let service = ProductionKzgService::new(config).await
        .context("Failed to initialize KZG service")?;
    
    println!("âœ… ç”Ÿäº§ç¯å¢ƒ KZG æœåŠ¡åˆå§‹åŒ–æˆåŠŸ");
    
    // å¯åŠ¨ HTTP æœåŠ¡å™¨
    start_http_server(service).await?;
    
    println!("ğŸ‰ æœåŠ¡å·²å®‰å…¨å…³é—­");
    Ok(())
}

/// åŠ è½½é…ç½®
async fn load_config() -> Result<ProductionConfig> {
    // ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶åŠ è½½é…ç½®
    let config_path = std::env::var("KZG_CONFIG_PATH")
        .unwrap_or_else(|_| "config/production.toml".to_string());
    
    if std::path::Path::new(&config_path).exists() {
        let config_str = tokio::fs::read_to_string(&config_path).await
            .context("Failed to read config file")?;
        
        let config: ProductionConfig = toml::from_str(&config_str)
            .context("Failed to parse config file")?;
        
        Ok(config)
    } else {
        info!("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {}", config_path);
        Ok(ProductionConfig::default())
    }
}