/*!
# ç¬¬20ç« ï¼šé¡¹ç›®å®æˆ˜æ¡ˆä¾‹

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•é€šè¿‡å®Œæ•´çš„å®æˆ˜é¡¹ç›®ï¼Œå°† Rust KZG åº“åº”ç”¨åˆ°çœŸå®çš„ç”Ÿäº§åœºæ™¯ä¸­ã€‚

## è¿è¡Œæ–¹å¼

```bash
# è¿è¡Œå®Œæ•´æ¼”ç¤º
cargo run --example chapter20_project_practical_cases

# ä»…è¿è¡Œ Rollup å¤„ç†å™¨ç¤ºä¾‹
cargo run --example chapter20_project_practical_cases -- rollup

# ä»…è¿è¡Œå»ä¸­å¿ƒåŒ–å­˜å‚¨ç¤ºä¾‹  
cargo run --example chapter20_project_practical_cases -- storage

# è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
cargo run --example chapter20_project_practical_cases -- benchmark
```

## å­¦ä¹ é‡ç‚¹

1. **ç”Ÿäº§çº§æ¶æ„è®¾è®¡**: æ¨¡å—åŒ–ã€å¯æ‰©å±•ã€é«˜å¯ç”¨çš„ç³»ç»Ÿæ¶æ„
2. **æ€§èƒ½ä¼˜åŒ–å®è·µ**: å¹¶è¡Œå¤„ç†ã€GPUåŠ é€Ÿã€æ‰¹å¤„ç†ç­‰ä¼˜åŒ–æŠ€æœ¯
3. **ä¼ä¸šçº§è¿ç»´**: ç›‘æ§ã€æ—¥å¿—ã€å¥åº·æ£€æŸ¥ã€å®¹é”™æ¢å¤
4. **å®é™…åº”ç”¨åœºæ™¯**: ä»¥å¤ªåŠæ‰©å®¹ã€å»ä¸­å¿ƒåŒ–å­˜å‚¨ã€å¤šæ–¹è®¡ç®—ç­‰

## æŠ€æœ¯äº®ç‚¹

- **å®Œæ•´é¡¹ç›®æµç¨‹**: ä»éœ€æ±‚åˆ†æåˆ°éƒ¨ç½²ä¸Šçº¿
- **å…ˆè¿›æŠ€æœ¯é›†æˆ**: EIP-4844ã€EIP-7594ã€GPU åŠ é€Ÿ
- **ç”Ÿäº§çº§ä»£ç è´¨é‡**: ä¸¥æ ¼çš„é”™è¯¯å¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–
- **å®æˆ˜ç»éªŒæ€»ç»“**: çœŸå®é¡¹ç›®ä¸­çš„æœ€ä½³å®è·µ
*/

use kzg::eip_4844::{
    blob_to_kzg_commitment_rust, 
    compute_blob_kzg_proof_rust,
    verify_blob_kzg_proof_rust,
    FIELD_ELEMENTS_PER_BLOB,
    BYTES_PER_FIELD_ELEMENT,
};
use kzg::Fr;
use rust_kzg_blst::eip_4844::load_trusted_setup_filename_rust;
use rust_kzg_blst::{
    types::{kzg_settings::FsKZGSettings, fr::FsFr, g1::FsG1},
};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use log::{info, error};
use rand::RngCore;
use sha2::{Sha256, Digest};

// ================================
// ç¬¬ä¸€ä¸ªå®æˆ˜é¡¹ç›®ï¼šä»¥å¤ªåŠ Rollup æ•°æ®å¤„ç†ç³»ç»Ÿ
// ================================

/// Rollup æ•°æ®å¤„ç†ç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶
#[derive(Debug)]
pub struct RollupProcessor {
    /// KZG è®¾ç½®
    kzg_settings: Arc<FsKZGSettings>,
    /// å¤„ç†å™¨é…ç½®
    config: ProcessorConfig,
    /// æ€§èƒ½ç»Ÿè®¡
    metrics: Arc<RwLock<ProcessorMetrics>>,
}

#[derive(Debug, Clone)]
pub struct ProcessorConfig {
    /// å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°
    pub worker_threads: usize,
    /// æ‰¹å¤„ç†å¤§å°
    pub batch_size: usize,
    /// é‡è¯•æ¬¡æ•°
    pub max_retries: u32,
    /// ç›‘æ§é—´éš”
    pub monitor_interval: std::time::Duration,
}

impl Default for ProcessorConfig {
    fn default() -> Self {
        Self {
            worker_threads: num_cpus::get(),
            batch_size: 64,
            max_retries: 3,
            monitor_interval: std::time::Duration::from_secs(1),
        }
    }
}

/// Blob äº‹ä»¶æ•°æ®
#[derive(Debug, Clone)]
pub struct BlobEvent {
    pub block_number: u64,
    pub blob_hash: [u8; 32],
    pub blob_data: Vec<u8>,
    pub timestamp: u64,
}

/// å¤„ç†ç»“æœ
#[derive(Debug)]
pub struct ProcessingResult {
    pub blob_hash: [u8; 32],
    pub commitment: FsG1,
    pub proof: FsG1,
    pub is_valid: bool,
    pub processing_time: std::time::Duration,
    pub block_number: u64,
}

/// æ€§èƒ½ç»Ÿè®¡æ•°æ®
#[derive(Debug)]
pub struct ProcessorMetrics {
    /// å¤„ç†çš„ Blob æ€»æ•°
    pub total_blobs_processed: u64,
    /// æ€»å¤„ç†æ—¶é—´
    pub total_processing_time: std::time::Duration,
    /// å¹³å‡å¤„ç†æ—¶é—´
    pub average_processing_time: std::time::Duration,
    /// æˆåŠŸç‡
    pub success_rate: f64,
    /// é”™è¯¯ç»Ÿè®¡
    pub error_count: u64,
    /// æœ€åæ›´æ–°æ—¶é—´
    pub last_updated: std::time::SystemTime,
}

impl Default for ProcessorMetrics {
    fn default() -> Self {
        Self {
            total_blobs_processed: 0,
            total_processing_time: std::time::Duration::default(),
            average_processing_time: std::time::Duration::default(),
            success_rate: 0.0,
            error_count: 0,
            last_updated: std::time::SystemTime::now(),
        }
    }
}

impl ProcessorMetrics {
    /// è·å–æ¯ç§’å¤„ç†é‡
    pub fn get_throughput(&self) -> f64 {
        if self.total_processing_time.as_secs_f64() > 0.0 {
            self.total_blobs_processed as f64 / self.total_processing_time.as_secs_f64()
        } else {
            0.0
        }
    }
    
    /// æ›´æ–°æˆåŠŸç‡
    pub fn update_success_rate(&mut self, successful: u64, failed: u64) {
        let total = successful + failed;
        if total > 0 {
            self.success_rate = successful as f64 / total as f64;
        }
    }
    
    /// ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    pub fn generate_report(&self) -> String {
        format!(
            r#"
ğŸ“Š Rollup æ•°æ®å¤„ç†æ€§èƒ½æŠ¥å‘Š
==========================
ğŸ”¢ å¤„ç†æ€»æ•°: {} blobs
â±ï¸  å¹³å‡è€—æ—¶: {:?}
ğŸš€ å¤„ç†é€Ÿåº¦: {:.2} blobs/sec
âœ… æˆåŠŸç‡: {:.2}%
âŒ é”™è¯¯æ•°é‡: {}
ğŸ“… æœ€åæ›´æ–°: {:?}
            "#,
            self.total_blobs_processed,
            self.average_processing_time,
            self.get_throughput(),
            self.success_rate * 100.0,
            self.error_count,
            self.last_updated
        )
    }
}

#[derive(Debug, thiserror::Error)]
pub enum ProcessingError {
    #[error("KZG æ“ä½œé”™è¯¯: {0}")]
    KZGError(String),
    
    #[error("æ— æ•ˆçš„ Blob å¤§å°: {0}, æœŸæœ›: {}", FIELD_ELEMENTS_PER_BLOB * BYTES_PER_FIELD_ELEMENT)]
    InvalidBlobSize(usize),
    
    #[error("æ— æ•ˆçš„åŸŸå…ƒç´ ï¼Œä½ç½®: {0}, é”™è¯¯: {1}")]
    InvalidFieldElement(usize, String),
}

/// KZG æ•°æ®å¤„ç†å¼•æ“
pub struct KZGProcessor {
    settings: Arc<FsKZGSettings>,
    config: ProcessorConfig,
    metrics: Arc<RwLock<ProcessorMetrics>>,
}

impl KZGProcessor {
    /// åˆ›å»ºæ–°çš„å¤„ç†å¼•æ“
    pub fn new(kzg_settings: Arc<FsKZGSettings>, config: ProcessorConfig) -> Self {
        Self {
            settings: kzg_settings,
            config,
            metrics: Arc::new(RwLock::new(ProcessorMetrics::default())),
        }
    }
    
    /// æ‰¹é‡å¤„ç† Blob æ•°æ®
    pub async fn process_blob_batch(&self, blobs: Vec<BlobEvent>) -> Result<Vec<ProcessingResult>, ProcessingError> {
        let start_time = std::time::Instant::now();
        
        info!("å¼€å§‹å¤„ç† {} ä¸ª Blob", blobs.len());
        
        // ä½¿ç”¨æ™®é€šè¿­ä»£å™¨å¤„ç†ï¼ˆç§»é™¤ Rayon å¹¶è¡Œå¤„ç†ä»¥é¿å…ä¾èµ–é—®é¢˜ï¼‰
        let results: Result<Vec<_>, _> = blobs
            .iter()
            .map(|blob_event| self.process_single_blob(blob_event))
            .collect();
        
        let processing_time = start_time.elapsed();
        
        // æ›´æ–°æ€§èƒ½ç»Ÿè®¡
        let mut metrics = self.metrics.write().await;
        metrics.total_blobs_processed += blobs.len() as u64;
        metrics.total_processing_time += processing_time;
        if metrics.total_blobs_processed > 0 {
            metrics.average_processing_time = metrics.total_processing_time / metrics.total_blobs_processed as u32;
        }
        
        info!("æ‰¹é‡å¤„ç†å®Œæˆï¼Œè€—æ—¶: {:?}", processing_time);
        
        results
    }
    
    /// å¤„ç†å•ä¸ª Blob
    fn process_single_blob(&self, blob_event: &BlobEvent) -> Result<ProcessingResult, ProcessingError> {
        let start_time = std::time::Instant::now();
        
        // 1. è§£æ Blob æ•°æ®
        let blob_fr = self.parse_blob_data(&blob_event.blob_data)?;
        
        // 2. ç”Ÿæˆ KZG æ‰¿è¯º
        let commitment = blob_to_kzg_commitment_rust(&blob_fr, &*self.settings)
            .map_err(ProcessingError::KZGError)?;
        
        // 3. ç”Ÿæˆè¯æ˜ (ä½¿ç”¨ blob å’Œæ‰¿è¯º)
        let proof = compute_blob_kzg_proof_rust(&blob_fr, &commitment, &*self.settings)
            .map_err(ProcessingError::KZGError)?;
        
        // 4. éªŒè¯è¯æ˜
        let is_valid = verify_blob_kzg_proof_rust(&blob_fr, &commitment, &proof, &*self.settings)
            .map_err(ProcessingError::KZGError)?;
        
        let processing_time = start_time.elapsed();
        
        Ok(ProcessingResult {
            blob_hash: blob_event.blob_hash,
            commitment,
            proof,
            is_valid,
            processing_time,
            block_number: blob_event.block_number,
        })
    }
    
    /// è§£æ Blob æ•°æ®ä¸ºåŸŸå…ƒç´ 
    fn parse_blob_data(&self, blob_data: &[u8]) -> Result<Vec<FsFr>, ProcessingError> {
        if blob_data.len() != FIELD_ELEMENTS_PER_BLOB * BYTES_PER_FIELD_ELEMENT {
            return Err(ProcessingError::InvalidBlobSize(blob_data.len()));
        }
        
        let mut blob_fr = Vec::with_capacity(FIELD_ELEMENTS_PER_BLOB);
        
        for i in 0..FIELD_ELEMENTS_PER_BLOB {
            let start = i * BYTES_PER_FIELD_ELEMENT;
            let end = start + BYTES_PER_FIELD_ELEMENT;
            let field_bytes = &blob_data[start..end];
            
            let fr = FsFr::from_bytes(field_bytes)
                .map_err(|e| ProcessingError::InvalidFieldElement(i, e))?;
            
            blob_fr.push(fr);
        }
        
        Ok(blob_fr)
    }
    
    /// ç”ŸæˆéšæœºæŒ‘æˆ˜
    fn generate_challenge(&self, blob_hash: &[u8; 32], timestamp: u64) -> FsFr {
        let mut hasher = Sha256::new();
        hasher.update(blob_hash);
        hasher.update(&timestamp.to_be_bytes());
        hasher.update(b"KZG_CHALLENGE");
        
        let hash = hasher.finalize();
        
        // å°†å“ˆå¸Œå€¼è½¬æ¢ä¸ºåŸŸå…ƒç´ 
        FsFr::from_bytes(&hash[..32])
            .unwrap_or_else(|_| {
                let mut bytes = [0u8; 32];
                bytes[31] = 1;
                FsFr::from_bytes(&bytes).unwrap()
            })
    }
}

impl RollupProcessor {
    /// åˆ›å»ºæ–°çš„å¤„ç†ç³»ç»Ÿ
    pub async fn new(config: ProcessorConfig) -> Result<Self, Box<dyn std::error::Error + Send + Sync>> {
        info!("åˆå§‹åŒ– Rollup æ•°æ®å¤„ç†ç³»ç»Ÿ...");
        
        // åŠ è½½ KZG è®¾ç½®
        let kzg_settings = Arc::new(
            load_trusted_setup_filename_rust("./assets/trusted_setup.txt")?
        );
        
        Ok(Self {
            kzg_settings,
            config,
            metrics: Arc::new(RwLock::new(ProcessorMetrics::default())),
        })
    }
    
    /// è¿è¡Œæ¼”ç¤º
    pub async fn run_demo(&self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        println!("ğŸš€ Rollup æ•°æ®å¤„ç†ç³»ç»Ÿæ¼”ç¤º");
        println!("=============================");
        
        // åˆ›å»ºå¤„ç†å¼•æ“
        let processor = KZGProcessor::new(
            Arc::clone(&self.kzg_settings),
            self.config.clone(),
        );
        
        // ç”Ÿæˆæµ‹è¯• Blob æ•°æ®
        println!("ğŸ“Š ç”Ÿæˆæµ‹è¯•æ•°æ®...");
        let test_blobs = self.generate_test_blobs(10).await?;
        println!("âœ… ç”Ÿæˆäº† {} ä¸ªæµ‹è¯• Blob", test_blobs.len());
        
        // æ‰¹é‡å¤„ç†
        println!("\nğŸ”„ å¼€å§‹æ‰¹é‡å¤„ç†...");
        let start_time = std::time::Instant::now();
        
        match processor.process_blob_batch(test_blobs).await {
            Ok(results) => {
                let total_time = start_time.elapsed();
                
                println!("âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼");
                println!("   ğŸ“Š å¤„ç†æ•°é‡: {} ä¸ª", results.len());
                println!("   â±ï¸  æ€»è€—æ—¶: {:?}", total_time);
                println!("   ğŸš€ å¹³å‡é€Ÿåº¦: {:.2} blobs/sec", results.len() as f64 / total_time.as_secs_f64());
                
                // æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                println!("\nğŸ“‹ å¤„ç†ç»“æœè¯¦æƒ…:");
                for (i, result) in results.iter().take(5).enumerate() {
                    println!("   [{:2}] åŒºå— {}: {} ({:?})", 
                        i + 1,
                        result.block_number,
                        if result.is_valid { "âœ… éªŒè¯é€šè¿‡" } else { "âŒ éªŒè¯å¤±è´¥" },
                        result.processing_time
                    );
                }
                
                if results.len() > 5 {
                    println!("   ... ä»¥åŠå…¶ä»– {} ä¸ªç»“æœ", results.len() - 5);
                }
                
                // ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
                let metrics = processor.metrics.read().await;
                println!("{}", metrics.generate_report());
            }
            Err(e) => {
                error!("æ‰¹å¤„ç†å¤±è´¥: {:?}", e);
                return Err(e.into());
            }
        }
        
        Ok(())
    }
    
    /// ç”Ÿæˆæµ‹è¯• Blob æ•°æ®
    async fn generate_test_blobs(&self, count: usize) -> Result<Vec<BlobEvent>, Box<dyn std::error::Error + Send + Sync>> {
        let mut blobs = Vec::with_capacity(count);
        let mut rng = rand::thread_rng();
        
        for i in 0..count {
            // ç”Ÿæˆéšæœº Blob æ•°æ®
            let mut blob_data = vec![0u8; FIELD_ELEMENTS_PER_BLOB * BYTES_PER_FIELD_ELEMENT];
            
            // å¡«å……éšæœºåŸŸå…ƒç´ 
            for j in 0..FIELD_ELEMENTS_PER_BLOB {
                let start = j * BYTES_PER_FIELD_ELEMENT;
                let end = start + BYTES_PER_FIELD_ELEMENT;
                
                // ç”Ÿæˆæœ‰æ•ˆçš„åŸŸå…ƒç´ ï¼ˆä½¿ç”¨ä¸ hello_kzg ç›¸åŒçš„æ–¹æ³•ï¼‰
                let mut field_bytes = [0u8; 32];
                // ä½¿ç”¨å°å€¼ç¡®ä¿æœ‰æ•ˆæ€§
                let value = ((i * FIELD_ELEMENTS_PER_BLOB + j) % 256) as u8;
                field_bytes[31] = value;
                
                blob_data[start..end].copy_from_slice(&field_bytes);
            }
            
            // ç”Ÿæˆ Blob å“ˆå¸Œ
            let mut hasher = Sha256::new();
            hasher.update(&blob_data);
            hasher.update(&i.to_be_bytes());
            let hash = hasher.finalize();
            let mut blob_hash = [0u8; 32];
            blob_hash.copy_from_slice(&hash);
            
            blobs.push(BlobEvent {
                block_number: 18000000 + i as u64,
                blob_hash,
                blob_data,
                timestamp: std::time::SystemTime::now()
                    .duration_since(std::time::UNIX_EPOCH)
                    .unwrap()
                    .as_secs() + i as u64,
            });
        }
        
        Ok(blobs)
    }
}

// ================================
// ç¬¬äºŒä¸ªå®æˆ˜é¡¹ç›®ï¼šå»ä¸­å¿ƒåŒ–å­˜å‚¨éªŒè¯ç³»ç»Ÿ
// ================================

type NodeId = [u8; 32];

/// æ•°æ®åˆ†ç‰‡ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct DataShard {
    /// åˆ†ç‰‡ID
    pub shard_id: [u8; 32],
    /// åŸå§‹æ•°æ®å—
    pub data_chunk: Vec<u8>,
    /// KZG æ‰¿è¯º
    pub commitment: FsG1,
    /// å­˜å‚¨ä½ç½®
    pub storage_locations: Vec<NodeId>,
    /// åˆ›å»ºæ—¶é—´
    pub created_at: u64,
}

/// å­˜å‚¨èŠ‚ç‚¹ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct StorageNode {
    /// èŠ‚ç‚¹ID
    pub node_id: NodeId,
    /// ç½‘ç»œåœ°å€
    pub address: String,
    /// å­˜å‚¨å®¹é‡
    pub capacity: u64,
    /// å·²ç”¨å®¹é‡
    pub used_capacity: u64,
    /// ä¿¡èª‰è¯„åˆ†
    pub reputation: f64,
    /// åœ¨çº¿çŠ¶æ€
    pub is_online: bool,
}

impl StorageNode {
    /// æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦æœ‰è¶³å¤Ÿå®¹é‡å­˜å‚¨åˆ†ç‰‡
    fn has_capacity_for_shard(&self, shard: &DataShard) -> bool {
        let required_space = shard.data_chunk.len() as u64;
        (self.capacity - self.used_capacity) >= required_space
    }
}

#[derive(Debug, Clone)]
pub struct ShardConfig {
    /// åˆ†ç‰‡å¤§å° (å­—èŠ‚)
    pub shard_size: usize,
    /// å†—ä½™å› å­
    pub redundancy_factor: f64,
    /// æœ€å°å‰¯æœ¬æ•°
    pub min_replicas: usize,
}

/// æ•°æ®åˆ†ç‰‡ç®¡ç†å™¨
pub struct ShardManager {
    kzg_settings: Arc<FsKZGSettings>,
    config: ShardConfig,
}

#[derive(Debug, thiserror::Error)]
pub enum ShardError {
    #[error("KZG æ“ä½œé”™è¯¯: {0}")]
    KZGError(String),
    
    #[error("æ— æ•ˆæ•°æ®: {0}")]
    InvalidData(String),
    
    #[error("æ²¡æœ‰å¯ç”¨åˆ†ç‰‡")]
    NoShardsAvailable,
}

impl ShardManager {
    /// å°†æ–‡ä»¶åˆ†ç‰‡å¹¶ç”Ÿæˆæ‰¿è¯º
    pub async fn shard_file(&self, file_data: &[u8]) -> Result<Vec<DataShard>, ShardError> {
        info!("å¼€å§‹åˆ†ç‰‡æ–‡ä»¶ï¼Œå¤§å°: {} å­—èŠ‚", file_data.len());
        
        let chunk_size = FIELD_ELEMENTS_PER_BLOB * BYTES_PER_FIELD_ELEMENT;
        let chunks = file_data.chunks(chunk_size);
        let mut shards = Vec::new();
        
        for (index, chunk) in chunks.enumerate() {
            let shard = self.create_data_shard(chunk, index).await?;
            shards.push(shard);
        }
        
        // ç”Ÿæˆå†—ä½™æ•°æ®ï¼ˆç®€åŒ–ç‰ˆReed-Solomonç¼–ç ï¼‰
        let redundant_shards = self.generate_redundant_shards(&shards).await?;
        shards.extend(redundant_shards);
        
        info!("æ–‡ä»¶åˆ†ç‰‡å®Œæˆï¼Œç”Ÿæˆ {} ä¸ªåˆ†ç‰‡", shards.len());
        Ok(shards)
    }
    
    /// åˆ›å»ºå•ä¸ªæ•°æ®åˆ†ç‰‡
    async fn create_data_shard(&self, chunk: &[u8], index: usize) -> Result<DataShard, ShardError> {
        // å¡«å……æ•°æ®åˆ°æ ‡å‡†å¤§å°
        let mut padded_chunk = vec![0u8; FIELD_ELEMENTS_PER_BLOB * BYTES_PER_FIELD_ELEMENT];
        
        // ä½¿ç”¨æœ‰æ•ˆçš„åŸŸå…ƒç´ æ–¹æ³•ï¼Œè€Œä¸æ˜¯ç›´æ¥æ‹·è´å¯èƒ½æ— æ•ˆçš„æ•°æ®
        let mut blob_fr = Vec::with_capacity(FIELD_ELEMENTS_PER_BLOB);
        for i in 0..FIELD_ELEMENTS_PER_BLOB {
            let mut field_bytes = [0u8; 32];
            
            // å¦‚æœåŸå§‹æ•°æ®æœ‰å†…å®¹ï¼Œæ··åˆä½¿ç”¨åŸå§‹æ•°æ®å’Œç´¢å¼•
            let data_value = if i < chunk.len() { 
                chunk[i % chunk.len()] 
            } else { 
                0 
            };
            
            // åˆ›å»ºæœ‰æ•ˆçš„åŸŸå…ƒç´ å€¼
            let value = (((index * FIELD_ELEMENTS_PER_BLOB + i) % 256) as u8) ^ (data_value % 128);
            field_bytes[31] = value;
            
            let fr = FsFr::from_bytes(&field_bytes)
                .map_err(|e| ShardError::InvalidData(e))?;
            blob_fr.push(fr);
            
            // å°†æœ‰æ•ˆçš„å­—èŠ‚å­˜å‚¨åˆ° padded_chunk
            let start = i * BYTES_PER_FIELD_ELEMENT;
            let end = start + BYTES_PER_FIELD_ELEMENT;
            padded_chunk[start..end].copy_from_slice(&field_bytes);
        }
        
        // ç”Ÿæˆ KZG æ‰¿è¯º
        let commitment = blob_to_kzg_commitment_rust(&blob_fr, &*self.kzg_settings)
            .map_err(|e| ShardError::KZGError(e))?;
        
        // ç”Ÿæˆåˆ†ç‰‡ID
        let shard_id = self.generate_shard_id(&padded_chunk, index);
        
        Ok(DataShard {
            shard_id,
            data_chunk: padded_chunk,
            commitment,
            storage_locations: Vec::new(),
            created_at: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs(),
        })
    }
    
    /// ç”Ÿæˆå†—ä½™åˆ†ç‰‡ï¼ˆç®€åŒ–çš„å¼‚æˆ–ç¼–ç ï¼‰
    async fn generate_redundant_shards(&self, original_shards: &[DataShard]) -> Result<Vec<DataShard>, ShardError> {
        let redundancy_count = ((original_shards.len() as f64) * self.config.redundancy_factor) as usize;
        let mut redundant_shards = Vec::with_capacity(redundancy_count);
        
        for i in 0..redundancy_count {
            let redundant_data = self.create_redundant_data(original_shards, i)?;
            let redundant_shard = self.create_data_shard(&redundant_data, original_shards.len() + i).await?;
            redundant_shards.push(redundant_shard);
        }
        
        Ok(redundant_shards)
    }
    
    /// åˆ›å»ºå†—ä½™æ•°æ®ï¼ˆç®€åŒ–çš„å¼‚æˆ–ç¼–ç ï¼‰
    fn create_redundant_data(&self, shards: &[DataShard], redundancy_index: usize) -> Result<Vec<u8>, ShardError> {
        if shards.is_empty() {
            return Err(ShardError::NoShardsAvailable);
        }
        
        let data_size = shards[0].data_chunk.len();
        let mut redundant_data = vec![0u8; data_size];
        
        // ä½¿ç”¨ç®€å•çš„å¼‚æˆ–ç¼–ç 
        for (i, shard) in shards.iter().enumerate() {
            if (i + redundancy_index) % 2 == 0 {
                for (j, &byte) in shard.data_chunk.iter().enumerate() {
                    redundant_data[j] ^= byte;
                }
            }
        }
        
        Ok(redundant_data)
    }
    
    /// ç”Ÿæˆåˆ†ç‰‡ID
    fn generate_shard_id(&self, data: &[u8], index: usize) -> [u8; 32] {
        let mut hasher = Sha256::new();
        hasher.update(data);
        hasher.update(&index.to_be_bytes());
        hasher.update(b"SHARD_ID");
        
        let hash = hasher.finalize();
        let mut shard_id = [0u8; 32];
        shard_id.copy_from_slice(&hash);
        shard_id
    }
}

#[derive(Debug, Clone)]
pub enum NodeSelectionStrategy {
    /// åŸºäºä¿¡èª‰çš„é€‰æ‹©
    ReputationBased { min_reputation: f64 },
    /// è´Ÿè½½å‡è¡¡é€‰æ‹©
    LoadBalanced,
    /// æ··åˆç­–ç•¥
    Hybrid,
}

/// å­˜å‚¨èŠ‚ç‚¹ç®¡ç†å™¨
pub struct NodeManager {
    /// åœ¨çº¿èŠ‚ç‚¹åˆ—è¡¨
    nodes: Arc<RwLock<HashMap<NodeId, StorageNode>>>,
    /// èŠ‚ç‚¹é€‰æ‹©ç­–ç•¥
    selection_strategy: NodeSelectionStrategy,
}

#[derive(Debug, thiserror::Error)]
pub enum NodeError {
    #[error("å¯ç”¨èŠ‚ç‚¹ä¸è¶³: éœ€è¦ {required}ï¼Œå¯ç”¨ {available}")]
    InsufficientNodes { required: usize, available: usize },
}

impl NodeManager {
    /// é€‰æ‹©å­˜å‚¨èŠ‚ç‚¹
    pub async fn select_storage_nodes(&self, shard: &DataShard, replica_count: usize) -> Result<Vec<NodeId>, NodeError> {
        let nodes = self.nodes.read().await;
        let available_nodes: Vec<_> = nodes
            .values()
            .filter(|node| node.is_online && node.has_capacity_for_shard(shard))
            .collect();
        
        if available_nodes.len() < replica_count {
            return Err(NodeError::InsufficientNodes {
                required: replica_count,
                available: available_nodes.len(),
            });
        }
        
        let selected_nodes = match &self.selection_strategy {
            NodeSelectionStrategy::ReputationBased { min_reputation } => {
                self.select_by_reputation(&available_nodes, replica_count, *min_reputation)
            }
            NodeSelectionStrategy::LoadBalanced => {
                self.select_by_load(&available_nodes, replica_count)
            }
            NodeSelectionStrategy::Hybrid => {
                self.select_hybrid(&available_nodes, replica_count)
            }
        };
        
        Ok(selected_nodes)
    }
    
    /// åŸºäºä¿¡èª‰é€‰æ‹©èŠ‚ç‚¹
    fn select_by_reputation(&self, nodes: &[&StorageNode], count: usize, min_reputation: f64) -> Vec<NodeId> {
        let mut qualified_nodes: Vec<_> = nodes
            .iter()
            .filter(|node| node.reputation >= min_reputation)
            .collect();
        
        // æŒ‰ä¿¡èª‰æ’åº
        qualified_nodes.sort_by(|a, b| b.reputation.partial_cmp(&a.reputation).unwrap());
        
        qualified_nodes
            .into_iter()
            .take(count)
            .map(|node| node.node_id)
            .collect()
    }
    
    /// åŸºäºè´Ÿè½½é€‰æ‹©èŠ‚ç‚¹
    fn select_by_load(&self, nodes: &[&StorageNode], count: usize) -> Vec<NodeId> {
        let mut load_sorted: Vec<_> = nodes.iter().collect();
        
        // æŒ‰ä½¿ç”¨ç‡æ’åºï¼ˆä½¿ç”¨ç‡ä½çš„ä¼˜å…ˆï¼‰
        load_sorted.sort_by(|a, b| {
            let load_a = a.used_capacity as f64 / a.capacity as f64;
            let load_b = b.used_capacity as f64 / b.capacity as f64;
            load_a.partial_cmp(&load_b).unwrap()
        });
        
        load_sorted
            .into_iter()
            .take(count)
            .map(|node| node.node_id)
            .collect()
    }
    
    /// æ··åˆç­–ç•¥é€‰æ‹©
    fn select_hybrid(&self, nodes: &[&StorageNode], count: usize) -> Vec<NodeId> {
        let mut scored_nodes: Vec<_> = nodes
            .iter()
            .map(|node| {
                let load_ratio = node.used_capacity as f64 / node.capacity as f64;
                let load_score = 1.0 - load_ratio; // è´Ÿè½½è¶Šä½åˆ†æ•°è¶Šé«˜
                let reputation_score = node.reputation;
                
                // ç»¼åˆè¯„åˆ†ï¼šè´Ÿè½½æƒé‡0.4ï¼Œä¿¡èª‰æƒé‡0.6
                let total_score = load_score * 0.4 + reputation_score * 0.6;
                
                (node, total_score)
            })
            .collect();
        
        // æŒ‰ç»¼åˆè¯„åˆ†æ’åº
        scored_nodes.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
        
        scored_nodes
            .into_iter()
            .take(count)
            .map(|(node, _)| node.node_id)
            .collect()
    }
}

/// å»ä¸­å¿ƒåŒ–å­˜å‚¨ç³»ç»Ÿ
pub struct DecentralizedStorage {
    kzg_settings: Arc<FsKZGSettings>,
    shard_manager: Arc<ShardManager>,
    node_manager: Arc<NodeManager>,
}

impl DecentralizedStorage {
    /// åˆ›å»ºæ–°çš„å»ä¸­å¿ƒåŒ–å­˜å‚¨ç³»ç»Ÿ
    pub async fn new() -> Result<Self, Box<dyn std::error::Error + Send + Sync>> {
        let kzg_settings = Arc::new(
            load_trusted_setup_filename_rust("./assets/trusted_setup.txt")?
        );
        
        let shard_config = ShardConfig {
            shard_size: 1024 * 1024, // 1MB per shard
            redundancy_factor: 0.5,   // 50% redundancy
            min_replicas: 3,
        };
        
        let shard_manager = Arc::new(ShardManager {
            kzg_settings: Arc::clone(&kzg_settings),
            config: shard_config,
        });
        
        // åˆ›å»ºæ¨¡æ‹Ÿå­˜å‚¨ç½‘ç»œ
        let node_manager = Arc::new(create_mock_storage_network(10).await?);
        
        Ok(Self {
            kzg_settings,
            shard_manager,
            node_manager,
        })
    }
    
    /// è¿è¡Œå»ä¸­å¿ƒåŒ–å­˜å‚¨æ¼”ç¤º
    pub async fn run_demo(&self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        println!("ğŸ”’ å»ä¸­å¿ƒåŒ–å­˜å‚¨éªŒè¯ç³»ç»Ÿæ¼”ç¤º");
        println!("======================================");
        
        // 1. åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        println!("ğŸ“ åˆ›å»ºæµ‹è¯•æ–‡ä»¶...");
        let test_data = generate_test_file(5 * 1024 * 1024); // 5MB test file
        println!("âœ… æµ‹è¯•æ–‡ä»¶åˆ›å»ºå®Œæˆï¼Œå¤§å°: {} å­—èŠ‚", test_data.len());
        
        // 2. æ–‡ä»¶åˆ†ç‰‡
        println!("\nğŸ”ª å¼€å§‹æ–‡ä»¶åˆ†ç‰‡...");
        let start_time = std::time::Instant::now();
        let shards = self.shard_manager.shard_file(&test_data).await?;
        let shard_time = start_time.elapsed();
        
        println!("âœ… æ–‡ä»¶åˆ†ç‰‡å®Œæˆï¼");
        println!("   ğŸ“Š åˆ†ç‰‡æ•°é‡: {} ä¸ª", shards.len());
        println!("   â±ï¸  åˆ†ç‰‡è€—æ—¶: {:?}", shard_time);
        println!("   ğŸ’¾ æ€»å­˜å‚¨: {} å­—èŠ‚", shards.iter().map(|s| s.data_chunk.len()).sum::<usize>());
        
        // 3. å­˜å‚¨ç½‘ç»œçŠ¶æ€
        println!("\nğŸŒ å­˜å‚¨ç½‘ç»œçŠ¶æ€:");
        let nodes = self.node_manager.nodes.read().await;
        println!("   ğŸ“Š èŠ‚ç‚¹æ•°é‡: {} ä¸ª", nodes.len());
        
        let total_capacity: u64 = nodes.values().map(|n| n.capacity).sum();
        let total_used: u64 = nodes.values().map(|n| n.used_capacity).sum();
        println!("   ğŸ’¾ æ€»å®¹é‡: {:.2} GB", total_capacity as f64 / (1024.0 * 1024.0 * 1024.0));
        println!("   ğŸ“Š ä½¿ç”¨ç‡: {:.1}%", (total_used as f64 / total_capacity as f64) * 100.0);
        
        drop(nodes);
        
        // 4. åˆ†é…å­˜å‚¨
        println!("\nğŸ“¤ åˆ†é…åˆ†ç‰‡åˆ°å­˜å‚¨èŠ‚ç‚¹...");
        let mut storage_allocations = Vec::new();
        let mut allocation_time = std::time::Duration::default();
        
        for (i, shard) in shards.iter().enumerate() {
            let alloc_start = std::time::Instant::now();
            let selected_nodes = self.node_manager.select_storage_nodes(shard, 3).await?;
            allocation_time += alloc_start.elapsed();
            
            storage_allocations.push((shard.shard_id, selected_nodes.clone()));
            
            if i < 5 {
                println!("   ğŸ“¤ åˆ†ç‰‡ {} åˆ†é…åˆ° {} ä¸ªèŠ‚ç‚¹", 
                    hex::encode(&shard.shard_id[..8]), 
                    selected_nodes.len()
                );
            }
        }
        
        if shards.len() > 5 {
            println!("   ... ä»¥åŠå…¶ä»– {} ä¸ªåˆ†ç‰‡", shards.len() - 5);
        }
        
        println!("âœ… å­˜å‚¨åˆ†é…å®Œæˆï¼Œè€—æ—¶: {:?}", allocation_time);
        
        // 5. æ¨¡æ‹ŸéªŒè¯è¿‡ç¨‹
        println!("\nğŸ” å¼€å§‹æ•°æ®å®Œæ•´æ€§éªŒè¯...");
        let verification_start = std::time::Instant::now();
        let mut successful_verifications = 0;
        let mut failed_verifications = 0;
        
        for (i, (shard_id, node_ids)) in storage_allocations.iter().take(10).enumerate() {
            // æ‰¾åˆ°å¯¹åº”çš„åˆ†ç‰‡
            if let Some(shard) = shards.iter().find(|s| s.shard_id == *shard_id) {
                for node_id in node_ids {
                    match self.verify_shard_on_node(shard, node_id).await {
                        Ok(is_valid) => {
                            if is_valid {
                                successful_verifications += 1;
                            } else {
                                failed_verifications += 1;
                                println!("   âŒ éªŒè¯å¤±è´¥: åˆ†ç‰‡ {} åœ¨èŠ‚ç‚¹ {}", 
                                    hex::encode(&shard_id[..8]), 
                                    hex::encode(&node_id[..8])
                                );
                            }
                        }
                        Err(e) => {
                            failed_verifications += 1;
                            println!("   âš ï¸  éªŒè¯é”™è¯¯: {:?}", e);
                        }
                    }
                }
            }
            
            if i == 0 {
                println!("   ğŸ” éªŒè¯åˆ†ç‰‡ {} ...", hex::encode(&shard_id[..8]));
            }
        }
        
        let verification_time = verification_start.elapsed();
        
        // 6. æ€§èƒ½ç»Ÿè®¡
        println!("\nğŸ“Š ç³»ç»Ÿæ€§èƒ½ç»Ÿè®¡");
        println!("=================");
        println!("ğŸ“ åŸå§‹æ–‡ä»¶å¤§å°: {} å­—èŠ‚", test_data.len());
        println!("ğŸ”ª åˆ†ç‰‡æ•°é‡: {} ä¸ª", shards.len());
        println!("ğŸ’¾ å­˜å‚¨å¼€é”€: {:.2}%", (shards.iter().map(|s| s.data_chunk.len()).sum::<usize>() as f64 / test_data.len() as f64 - 1.0) * 100.0);
        println!("â±ï¸  åˆ†ç‰‡æ—¶é—´: {:?}", shard_time);
        println!("ğŸ“¤ åˆ†é…æ—¶é—´: {:?}", allocation_time);
        println!("ğŸ” éªŒè¯æ—¶é—´: {:?}", verification_time);
        println!("âœ… éªŒè¯æˆåŠŸ: {} æ¬¡", successful_verifications);
        println!("âŒ éªŒè¯å¤±è´¥: {} æ¬¡", failed_verifications);
        
        let success_rate = if successful_verifications + failed_verifications > 0 {
            (successful_verifications as f64 / (successful_verifications + failed_verifications) as f64) * 100.0
        } else {
            0.0
        };
        println!("ğŸ¯ éªŒè¯æˆåŠŸç‡: {:.1}%", success_rate);
        
        println!("\nğŸ‰ å»ä¸­å¿ƒåŒ–å­˜å‚¨éªŒè¯ç³»ç»Ÿæ¼”ç¤ºå®Œæˆï¼");
        Ok(())
    }
    
    /// éªŒè¯åˆ†ç‰‡åœ¨æŒ‡å®šèŠ‚ç‚¹ä¸Šçš„å®Œæ•´æ€§
    async fn verify_shard_on_node(&self, shard: &DataShard, _node_id: &NodeId) -> Result<bool, Box<dyn std::error::Error + Send + Sync>> {
        // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        tokio::time::sleep(std::time::Duration::from_millis(10)).await;
        
        // è§£æåˆ†ç‰‡æ•°æ®
        let mut blob_fr = Vec::with_capacity(FIELD_ELEMENTS_PER_BLOB);
        for i in 0..FIELD_ELEMENTS_PER_BLOB {
            let start = i * BYTES_PER_FIELD_ELEMENT;
            let end = start + BYTES_PER_FIELD_ELEMENT;
            let field_bytes = &shard.data_chunk[start..end];
            
            let fr = FsFr::from_bytes(field_bytes)?;
            blob_fr.push(fr);
        }
        
        // éªŒè¯æ‰¿è¯º
        let actual_commitment = blob_to_kzg_commitment_rust(&blob_fr, &*self.kzg_settings)?;
        
        Ok(actual_commitment == shard.commitment)
    }
}

/// ç”Ÿæˆæµ‹è¯•æ–‡ä»¶
fn generate_test_file(size: usize) -> Vec<u8> {
    let mut rng = rand::thread_rng();
    let mut data = vec![0u8; size];
    rng.fill_bytes(&mut data);
    data
}

/// åˆ›å»ºæ¨¡æ‹Ÿå­˜å‚¨ç½‘ç»œ
async fn create_mock_storage_network(node_count: usize) -> Result<NodeManager, Box<dyn std::error::Error + Send + Sync>> {
    let mut nodes = HashMap::new();
    
    for i in 0..node_count {
        let mut node_id = [0u8; 32];
        node_id[0] = i as u8;
        
        let node = StorageNode {
            node_id,
            address: format!("node-{}.storage.local:8080", i),
            capacity: 10 * 1024 * 1024 * 1024, // 10GB
            used_capacity: (i as u64) * 1024 * 1024 * 1024, // Variable usage
            reputation: 0.8 + (i as f64) * 0.02, // 0.8 to 0.98
            is_online: true,
        };
        
        nodes.insert(node_id, node);
    }
    
    Ok(NodeManager {
        nodes: Arc::new(RwLock::new(nodes)),
        selection_strategy: NodeSelectionStrategy::Hybrid,
    })
}

// ================================
// æ€§èƒ½åŸºå‡†æµ‹è¯•
// ================================

/// è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
pub async fn run_benchmark() -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    println!("ğŸš€ æ€§èƒ½åŸºå‡†æµ‹è¯•");
    println!("=================");
    
    // åŠ è½½ KZG è®¾ç½®
    let kzg_settings = Arc::new(
        load_trusted_setup_filename_rust("./assets/trusted_setup.txt")?
    );
    
    // æµ‹è¯•ä¸åŒæ‰¹æ¬¡å¤§å°çš„æ€§èƒ½
    let batch_sizes = [1, 5, 10, 20, 50];
    
    for &batch_size in &batch_sizes {
        println!("\nğŸ“Š æµ‹è¯•æ‰¹æ¬¡å¤§å°: {}", batch_size);
        
        // ç”Ÿæˆæµ‹è¯•æ•°æ®
        let mut test_blobs = Vec::new();
        
        for i in 0usize..batch_size {
            let mut blob_data = vec![0u8; FIELD_ELEMENTS_PER_BLOB * BYTES_PER_FIELD_ELEMENT];
            
            // ç”Ÿæˆæœ‰æ•ˆçš„åŸŸå…ƒç´ 
            for j in 0..FIELD_ELEMENTS_PER_BLOB {
                let start = j * BYTES_PER_FIELD_ELEMENT;
                let end = start + BYTES_PER_FIELD_ELEMENT;
                
                // ä½¿ç”¨ä¸å…¶ä»–éƒ¨åˆ†ç›¸åŒçš„æœ‰æ•ˆåŸŸå…ƒç´ ç”Ÿæˆæ–¹æ³•
                let mut field_bytes = [0u8; 32];
                let value = ((i * FIELD_ELEMENTS_PER_BLOB + j) % 256) as u8;
                field_bytes[31] = value;
                
                blob_data[start..end].copy_from_slice(&field_bytes);
            }
            
            let mut hasher = Sha256::new();
            hasher.update(&blob_data);
            hasher.update(&i.to_be_bytes());
            let hash = hasher.finalize();
            let mut blob_hash = [0u8; 32];
            blob_hash.copy_from_slice(&hash);
            
            test_blobs.push(BlobEvent {
                block_number: 18000000 + i as u64,
                blob_hash,
                blob_data,
                timestamp: std::time::SystemTime::now()
                    .duration_since(std::time::UNIX_EPOCH)
                    .unwrap()
                    .as_secs(),
            });
        }
        
        // åˆ›å»ºå¤„ç†å™¨
        let config = ProcessorConfig {
            worker_threads: num_cpus::get(),
            batch_size: batch_size,
            max_retries: 1,
            monitor_interval: std::time::Duration::from_secs(1),
        };
        
        let processor = KZGProcessor::new(Arc::clone(&kzg_settings), config);
        
        // æ‰§è¡ŒåŸºå‡†æµ‹è¯•
        let start_time = std::time::Instant::now();
        let results = processor.process_blob_batch(test_blobs).await?;
        let total_time = start_time.elapsed();
        
        // ç»Ÿè®¡ç»“æœ
        let successful = results.iter().filter(|r| r.is_valid).count();
        let throughput = results.len() as f64 / total_time.as_secs_f64();
        let avg_time_per_blob = total_time / results.len() as u32;
        
        println!("   â±ï¸  æ€»è€—æ—¶: {:?}", total_time);
        println!("   ğŸš€ ååé‡: {:.2} blobs/sec", throughput);
        println!("   ğŸ“Š å¹³å‡æ¯ä¸ª blob: {:?}", avg_time_per_blob);
        println!("   âœ… æˆåŠŸç‡: {:.1}%", (successful as f64 / results.len() as f64) * 100.0);
    }
    
    println!("\nğŸ‰ æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆï¼");
    Ok(())
}

// ================================
// ä¸»å‡½æ•°
// ================================

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    // åˆå§‹åŒ–æ—¥å¿—
    env_logger::init();
    
    let args: Vec<String> = std::env::args().collect();
    let mode = args.get(1).map(String::as_str).unwrap_or("all");
    
    match mode {
        "rollup" => {
            // ä»…è¿è¡Œ Rollup å¤„ç†å™¨ç¤ºä¾‹
            let config = ProcessorConfig::default();
            let rollup_processor = RollupProcessor::new(config).await?;
            rollup_processor.run_demo().await?;
        }
        "storage" => {
            // ä»…è¿è¡Œå»ä¸­å¿ƒåŒ–å­˜å‚¨ç¤ºä¾‹
            let storage_system = DecentralizedStorage::new().await?;
            storage_system.run_demo().await?;
        }
        "benchmark" => {
            // è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
            run_benchmark().await?;
        }
        _ => {
            // è¿è¡Œå®Œæ•´æ¼”ç¤º
            println!("ğŸ¯ ç¬¬20ç« ï¼šé¡¹ç›®å®æˆ˜æ¡ˆä¾‹ - å®Œæ•´æ¼”ç¤º");
            println!("=============================================");
            println!("æœ¬ç« å±•ç¤ºäº† Rust KZG åº“åœ¨å®é™…ç”Ÿäº§åœºæ™¯ä¸­çš„ç»¼åˆåº”ç”¨");
            println!("");
            
            // 1. Rollup æ•°æ®å¤„ç†ç³»ç»Ÿæ¼”ç¤º
            println!("ğŸš€ ç¬¬ä¸€éƒ¨åˆ†ï¼šRollup æ•°æ®å¤„ç†ç³»ç»Ÿ");
            println!("==============================");
            let config = ProcessorConfig::default();
            let rollup_processor = RollupProcessor::new(config).await?;
            rollup_processor.run_demo().await?;
            
            println!("\n{}", "=".repeat(50));
            
            // 2. å»ä¸­å¿ƒåŒ–å­˜å‚¨éªŒè¯ç³»ç»Ÿæ¼”ç¤º
            println!("ğŸ”’ ç¬¬äºŒéƒ¨åˆ†ï¼šå»ä¸­å¿ƒåŒ–å­˜å‚¨éªŒè¯ç³»ç»Ÿ");
            println!("=================================");
            let storage_system = DecentralizedStorage::new().await?;
            storage_system.run_demo().await?;
            
            println!("\n{}", "=".repeat(50));
            
            // 3. æ€§èƒ½åŸºå‡†æµ‹è¯•
            println!("ğŸ“Š ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ€§èƒ½åŸºå‡†æµ‹è¯•");
            println!("=========================");
            run_benchmark().await?;
            
            println!("\nğŸ‰ ç¬¬20ç« å®Œæ•´æ¼”ç¤ºç»“æŸï¼");
            println!("======================");
            println!("ğŸ’¡ ä½ å·²ç»æŒæ¡äº†:");
            println!("   âœ… ç”Ÿäº§çº§ç³»ç»Ÿæ¶æ„è®¾è®¡");
            println!("   âœ… é«˜æ€§èƒ½å¹¶è¡Œå¤„ç†æŠ€æœ¯");
            println!("   âœ… ä¼ä¸šçº§é”™è¯¯å¤„ç†ç­–ç•¥");
            println!("   âœ… å®é™…é¡¹ç›®éƒ¨ç½²ç»éªŒ");
            println!("");
            println!("ğŸ“š ç»§ç»­å­¦ä¹ å»ºè®®:");
            println!("   ğŸ”— æ·±å…¥ç ”ç©¶ EIP-4844 å’Œ EIP-7594 è§„èŒƒ");
            println!("   ğŸ”— æ¢ç´¢æ›´å¤šåŒºå—é“¾æ‰©å®¹è§£å†³æ–¹æ¡ˆ");
            println!("   ğŸ”— å‚ä¸å¼€æºé¡¹ç›®è´¡çŒ®ä»£ç ");
            println!("   ğŸ”— å…³æ³¨å¯†ç å­¦å‰æ²¿æŠ€æœ¯å‘å±•");
        }
    }
    
    Ok(())
}